import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO
import os 
import json
import gspread
import logging
import time

# ==============================================================================
# ä¾è³´åº«å°å…¥èˆ‡ç’°å¢ƒåˆå§‹åŒ–
# ==============================================================================

# å¼•å…¥ Google Cloud Storage (GCS) åº«ï¼Œç”¨æ–¼é™„ä»¶ä¸Šå‚³èˆ‡ç°½ç«  URL ç”Ÿæˆ
from google.cloud import storage

# ç¢ºä¿ openpyxl åº«å·²å®‰è£ (ç”¨æ–¼ Excel åŒ¯å‡º)

# --- æ‡‰ç”¨ç¨‹å¼è¨­å®šèˆ‡å¸¸æ•¸å®šç¾© ---
# ä¾ç…§æ‚¨çš„è¦æ±‚ï¼Œç‰ˆæœ¬è™Ÿå›å¾©ä¸¦é–å®šåœ¨ v2.2.5
APP_VERSION = "v2.2.5" 
STATUS_OPTIONS = ["å¾…æ¡è³¼", "å·²ä¸‹å–®", "å·²æ”¶è²¨", "å–æ¶ˆ"] # å ±åƒ¹ç‹€æ…‹é¸é …
DATE_FORMAT = "%Y-%m-%d"                            # æ—¥æœŸæ¨™æº–æ ¼å¼
DATETIME_FORMAT = "%Y-%m-%d %H:%M:%S"               # æ™‚é–“æˆ³æ¨™æº–æ ¼å¼

# --- Google Cloud Storage (GCS) é…ç½® ---
# âš ï¸ æ³¨æ„ï¼šè«‹ç¢ºä¿æ‚¨çš„ GCE æœå‹™å¸³æˆ¶æœ‰ Storage Object Admin/Creator æ¬Šé™
GCS_BUCKET_NAME = "procurement-attachments-bucket"
GCS_ATTACHMENT_FOLDER = "attachments"

# --- æ—¥èªŒé…ç½®ï¼šç”¨æ–¼ Streamlit å¾Œç«¯ç´€éŒ„ï¼Œæ–¹ä¾¿é™¤éŒ¯ ---
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- æ•¸æ“šæºé…ç½®ï¼šå„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å– Google Sheets è³‡è¨Š ---
if "GCE_SHEET_URL" in os.environ:
    SHEET_URL = os.environ["GCE_SHEET_URL"]
    try:
        # GSheets æ†‘è­‰è·¯å¾‘ï¼Œç”¨æ–¼ Gspread é€£ç·šèˆ‡ GCS Signed URL ç°½ç½²
        GSHEETS_CREDENTIALS = os.environ["GSHEETS_CREDENTIALS_PATH"] 
    except KeyError:
        logger.error("GSHEETS_CREDENTIALS_PATH is missing in environment.")
        st.error("âŒ åš´é‡éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GSHEETS_CREDENTIALS_PATH ç’°å¢ƒè®Šæ•¸ã€‚")
        GSHEETS_CREDENTIALS = None 
else:
    # é GCE ç’°å¢ƒä¸‹çš„å‚™ç”¨é…ç½®
    try:
        SHEET_URL = st.secrets["app_config"]["sheet_url"]
        GSHEETS_CREDENTIALS = None 
    except KeyError:
        SHEET_URL = None
        GSHEETS_CREDENTIALS = None
        
DATA_SHEET_NAME = "æ¡è³¼ç¸½è¡¨"     # å­˜æ”¾å ±åƒ¹æ•¸æ“šçš„å·¥ä½œè¡¨åç¨±
METADATA_SHEET_NAME = "å°ˆæ¡ˆè¨­å®š" # å­˜æ”¾å°ˆæ¡ˆè¨­å®š (äº¤æœŸ, ç·©è¡å¤©æ•¸) çš„å·¥ä½œè¡¨åç¨±


# --- Streamlit é é¢è¨­å®š ---
st.set_page_config(
    page_title=f"å°ˆæ¡ˆæ¡è³¼å°å¹«æ‰‹ {APP_VERSION}", 
    page_icon="ğŸ› ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS æ¨£å¼å„ªåŒ– ---
# æ¢å¾©è¼ƒç‚ºåŸºç¤çš„æ¨£å¼ï¼Œå–æ¶ˆ V2.1.6 çš„ç‰¹æ®Šæ ¼å¼
CUSTOM_CSS = """
<style>
    .block-container { padding-top: 1rem; padding-bottom: 2rem; }
    
    .status-ok { color: #4CAF50; font-weight: bold; }
    .status-risk { color: #FF4B4B; font-weight: bold; }
    
    /* èª¿æ•´ DataFrame ç·¨è¼¯å™¨çš„å­—é«”å¤§å° */
    .stDataFrame { font-size: 14px; }
</style>
"""


# ==============================================================================
# è¼”åŠ©å‡½å¼å€
# ==============================================================================

# --- èº«ä»½é©—è­‰èˆ‡ç™»å‡º ---
def logout():
    """æ¸…é™¤ Session State ä¸¦é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼ä»¥ç™»å‡ºã€‚"""
    st.session_state["authenticated"] = False
    for key in ['data', 'project_metadata', 'edited_dataframes']:
        if key in st.session_state: del st.session_state[key]
    st.rerun()

def login_form():
    """é¡¯ç¤ºç™»å…¥è¡¨å–®ä¸¦é€²è¡Œå¯†ç¢¼é©—è­‰ã€‚"""
    DEFAULT_USERNAME = os.environ.get("AUTH_USERNAME", "dev_user")
    DEFAULT_PASSWORD = os.environ.get("AUTH_PASSWORD", "dev_pwd")
    credentials = {"username": DEFAULT_USERNAME, "password": DEFAULT_PASSWORD}

    if "authenticated" not in st.session_state:
        st.session_state["authenticated"] = False
        
    if st.session_state["authenticated"]: return

    st.markdown("<br><br>", unsafe_allow_html=True)
    _, col_center, _ = st.columns([1, 2, 1])
    with col_center:
        with st.container(border=True):
            st.title("ğŸ” ç³»çµ±ç™»å…¥")
            username = st.text_input("ç”¨æˆ¶å", value=credentials["username"], disabled=True)
            password = st.text_input("å¯†ç¢¼", type="password")
            if st.button("ç™»å…¥", type="primary", use_container_width=True):
                if username.strip() == credentials["username"].strip() and password == credentials["password"]:
                    st.session_state["authenticated"] = True
                    st.rerun()
                else:
                    st.error("å¯†ç¢¼éŒ¯èª¤")
    st.stop() 


# --- GCS æœå‹™ç›¸é—œå‡½å¼ ---
def get_storage_client():
    """
    ç²å– GCS å®¢æˆ¶ç«¯ã€‚å„ªå…ˆä½¿ç”¨ Service Account JSON æª”æ¡ˆé€²è¡Œé©—è­‰ã€‚
    """
    if GSHEETS_CREDENTIALS and os.path.exists(GSHEETS_CREDENTIALS):
        try:
            return storage.Client.from_service_account_json(GSHEETS_CREDENTIALS)
        except Exception as e:
            logger.error(f"GCS Client initialization failed with JSON: {e}")
            return storage.Client() 
    return storage.Client()

def upload_attachment_to_gcs(file_obj, next_id):
    """
    å°‡æª”æ¡ˆä¸Šå‚³åˆ° GCS ç§æœ‰å„²å­˜æ¡¶ã€‚
    """
    if not file_obj: return None
    try:
        client = get_storage_client()
        bucket = client.bucket(GCS_BUCKET_NAME)
        ext = os.path.splitext(file_obj.name)[1]
        ts = datetime.now().strftime("%Y%m%d%H%M%S")
        blob_name = f"{GCS_ATTACHMENT_FOLDER}/{next_id}_{ts}{ext}"
        blob = bucket.blob(blob_name)
        file_obj.seek(0)
        
        content_type = file_obj.type if file_obj.type else 'application/octet-stream'
        blob.upload_from_file(file_obj, content_type=content_type)
        
        logger.info(f"Attachment uploaded: {blob_name}")
        return f"gs://{GCS_BUCKET_NAME}/{blob_name}"
    except Exception as e:
        logger.exception("GCS upload failed.")
        st.error(f"âŒ é™„ä»¶ä¸Šå‚³å¤±æ•—ã€‚è«‹æª¢æŸ¥ GCS æ¬Šé™é…ç½®æˆ– Bucket åç¨±ã€‚éŒ¯èª¤: {e}")
        return None

@st.cache_data(ttl=3600, show_spinner=False)
def generate_signed_url_cached(gcs_uri):
    """
    ç‚º GCS ç§æœ‰ç‰©ä»¶ç”Ÿæˆå¸¶æœ‰ç°½ç« çš„è‡¨æ™‚ URL (Signed URL)ã€‚
    """
    if not gcs_uri or not gcs_uri.startswith("gs://"): return None
    try:
        path_part = gcs_uri[5:]
        parts = path_part.split('/', 1)
        if len(parts) != 2: return None
            
        client = get_storage_client()
        bucket = client.bucket(parts[0])
        blob = bucket.blob(parts[1])
        
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(hours=1),
            method="GET"
        )
        return url
        
    except Exception as e:
        logger.error(f"Failed to generate Signed URL for {gcs_uri}: {e}")
        return None

# --- æ•¸æ“šå·¥å…· ---
def add_business_days(start_date, num_days):
    """è¨ˆç®—å·¥ä½œæ—¥ (è·³éé€±æœ«)ã€‚"""
    current_date = start_date
    days_added = 0
    while days_added < num_days:
        current_date += timedelta(days=1)
        if current_date.weekday() < 5: 
            days_added += 1
    return current_date

@st.cache_data
def convert_df_to_excel(df):
    """è½‰æ› DataFrame ç‚º Excel æ ¼å¼ä¾›ä¸‹è¼‰ã€‚"""
    # é€™è£¡ä¿ç•™æ‰€æœ‰æ¬„ä½ï¼Œå› ç‚ºè¦æ¢å¾©å®Œæ•´æ€§
    df_export = df.copy().fillna("")
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_export.to_excel(writer, index=False, sheet_name='æ¡è³¼å ±åƒ¹ç¸½è¡¨')
    return output.getvalue()


# --- Gspread æ•¸æ“šè™•ç† ---
@st.cache_data(ttl=600, show_spinner="æ­£åœ¨åŒæ­¥ Google Sheets æ•¸æ“š...")
def load_data_from_sheets():
    """å¾ Google Sheets è¼‰å…¥æ‰€æœ‰æ¡è³¼æ•¸æ“šèˆ‡å°ˆæ¡ˆè¨­å®šã€‚"""
    if not SHEET_URL:
        st.warning("âš ï¸ Google Sheets URL å°šæœªé…ç½®ã€‚")
        return pd.DataFrame(), {}
        
    try:
        # é€£ç·šèªè­‰
        gc = gspread.service_account(filename=GSHEETS_CREDENTIALS) if GSHEETS_CREDENTIALS else gspread.service_account()
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 1. è®€å–æ¡è³¼ç¸½è¡¨ (Data) ---
        data_ws = sh.worksheet(DATA_SHEET_NAME)
        data_records = data_ws.get_all_records()
        data_df = pd.DataFrame(data_records)

        # ç¢ºä¿æ ¸å¿ƒæ¬„ä½å­˜åœ¨
        required_cols = ['ID', 'é¸å–', 'å°ˆæ¡ˆåç¨±', 'å°ˆæ¡ˆé …ç›®', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 'é è¨ˆäº¤è²¨æ—¥', 'ç‹€æ…‹', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥', 'æœ€å¾Œä¿®æ”¹æ™‚é–“', 'é™„ä»¶URL', 'æ¨™è¨˜åˆªé™¤']
        for col in required_cols:
            if col not in data_df.columns: 
                data_df[col] = "" 
        
        # è³‡æ–™é¡å‹è½‰æ›
        data_df['ID'] = pd.to_numeric(data_df['ID'], errors='coerce').astype('Int64')
        data_df['å–®åƒ¹'] = pd.to_numeric(data_df['å–®åƒ¹'], errors='coerce').fillna(0).astype('float')
        data_df['æ•¸é‡'] = pd.to_numeric(data_df['æ•¸é‡'], errors='coerce').fillna(1).astype('Int64')
        data_df['ç¸½åƒ¹'] = pd.to_numeric(data_df['ç¸½åƒ¹'], errors='coerce').fillna(0).astype('float')
        
        data_df['é¸å–'] = data_df['é¸å–'].astype(str).str.upper() == 'TRUE'
        data_df['æ¨™è¨˜åˆªé™¤'] = data_df['æ¨™è¨˜åˆªé™¤'].astype(str).str.upper() == 'TRUE'
        
        # æ¢å¾© V2.2.5 é‚è¼¯ï¼šä¸å¼·åˆ¶è½‰æ›æ—¥æœŸç‚º datetime ç‰©ä»¶ï¼Œé¿å…ç·¨è¼¯å™¨æ ¼å¼å•é¡Œ
        # ä¿æŒç‚ºå­—ä¸²æˆ–è®“ Pandas è‡ªå‹•æ¨æ–·ï¼Œä½†ä¸åœ¨ data_editor ä¸­å¼·åˆ¶æŒ‡å®š DateColumn
        
        logger.info(f"Loaded {len(data_df)} records.")

        # --- 2. è®€å–å°ˆæ¡ˆè¨­å®š (Metadata) ---
        meta_records = sh.worksheet(METADATA_SHEET_NAME).get_all_records()
        project_metadata = {}
        for row in meta_records:
            name = row.get('å°ˆæ¡ˆåç¨±')
            if name:
                project_metadata[name] = {
                    'due_date': pd.to_datetime(str(row.get('å°ˆæ¡ˆäº¤è²¨æ—¥'))).date(),
                    'buffer_days': int(row.get('ç·©è¡å¤©æ•¸', 7)),
                    'last_modified': str(row.get('æœ€å¾Œä¿®æ”¹', ''))
                }
        
        st.toast("âœ… æ•¸æ“šå·²å¾ Google Sheets æ›´æ–°", icon="â˜ï¸")
        return data_df, project_metadata
    except Exception as e:
        logger.exception("Google Sheets æ•¸æ“šè¼‰å…¥å¤±æ•—") 
        st.error(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼éŒ¯èª¤: {e}")
        st.session_state.data_load_failed = True
        return pd.DataFrame(), {}

def write_data_to_sheets(df, meta):
    """å°‡ä¿®æ”¹å¾Œçš„æ•¸æ“šèˆ‡å°ˆæ¡ˆè¨­å®šå¯«å› Google Sheetsã€‚"""
    if st.session_state.get('data_load_failed', False): return False
    try:
        gc = gspread.service_account(filename=GSHEETS_CREDENTIALS)
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 1. å¯«å…¥æ¡è³¼ç¸½è¡¨ ---
        # ç§»é™¤å‰ç«¯ç´”é¡¯ç¤ºçš„æ¬„ä½ï¼Œä¿ç•™åŸå§‹æ¬„ä½ (åŒ…å« é™„ä»¶URL)
        cols_to_drop = ['äº¤æœŸç‹€æ…‹', 'é™„ä»¶é€£çµ'] 
        # æ³¨æ„ï¼šV2.2.5 æ‡‰è©²æœƒä¿ç•™ 'æ¨™è¨˜åˆªé™¤' ç‹€æ…‹å¯«å›ï¼Œæˆ–è€…ç”± delete function è™•ç†
        # é€™è£¡ç‚ºäº†å®‰å…¨ï¼Œæˆ‘å€‘éæ¿¾æ‰ UI ç”¢ç”Ÿçš„è‡¨æ™‚æ¬„ä½
        
        export_df = df.copy()
        for c in cols_to_drop:
            if c in export_df.columns:
                export_df = export_df.drop(columns=[c])
        
        export_df = export_df.fillna("")
        
        # ç¢ºä¿æ—¥æœŸæ ¼å¼æ­£ç¢º
        for col in export_df.columns:
            if pd.api.types.is_datetime64_any_dtype(export_df[col]):
                export_df[col] = export_df[col].dt.strftime(DATE_FORMAT)

        data_ws = sh.worksheet(DATA_SHEET_NAME)
        data_ws.clear()
        data_ws.update([export_df.columns.tolist()] + export_df.values.tolist())
        
        # --- 2. å¯«å…¥å°ˆæ¡ˆè¨­å®š ---
        meta_list = [{'å°ˆæ¡ˆåç¨±': k, 'å°ˆæ¡ˆäº¤è²¨æ—¥': v['due_date'].strftime(DATE_FORMAT), 'ç·©è¡å¤©æ•¸': v['buffer_days'], 'æœ€å¾Œä¿®æ”¹': v['last_modified']} for k,v in meta.items()]
        meta_df = pd.DataFrame(meta_list)
        
        metadata_ws = sh.worksheet(METADATA_SHEET_NAME)
        metadata_ws.clear()
        if not meta_df.empty:
            metadata_ws.update([meta_df.columns.tolist()] + meta_df.values.tolist())
            
        st.cache_data.clear()
        logger.info("Data successfully written to Google Sheets.")
        return True
    except Exception as e:
        logger.exception("Google Sheets write operation failed.")
        st.error(f"âŒ æ•¸æ“šå¯«å›å¤±æ•—ï¼è«‹æª¢æŸ¥æ¬Šé™ã€‚éŒ¯èª¤: {e}")
        return False


# --- æ•¸æ“šè¨ˆç®—èˆ‡æŒ‡æ¨™ ---
def calculate_latest_arrival(df, meta):
    """è¨ˆç®—æ¯å€‹æ¡è³¼é …ç›®çš„æœ€æ…¢åˆ°è²¨æ—¥ (å°ˆæ¡ˆäº¤æœŸ - ç·©è¡å¤©æ•¸)ã€‚"""
    if df.empty or not meta: return df
    meta_df = pd.DataFrame.from_dict(meta, orient='index').reset_index().rename(columns={'index': 'å°ˆæ¡ˆåç¨±'})
    meta_df['due_date'] = pd.to_datetime(meta_df['due_date']).dt.date
    df = pd.merge(df, meta_df[['å°ˆæ¡ˆåç¨±', 'due_date', 'buffer_days']], on='å°ˆæ¡ˆåç¨±', how='left')
    
    # è¨ˆç®—é‚è¼¯
    df['temp_due_date'] = pd.to_datetime(df['due_date'])
    df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'] = (df['temp_due_date'] - pd.to_timedelta(df['buffer_days'].astype(int), unit='D')).dt.strftime(DATE_FORMAT)
    
    return df.drop(columns=['due_date', 'buffer_days', 'temp_due_date'], errors='ignore')

def calculate_project_budget(df, project_name):
    """è¨ˆç®—å–®ä¸€å°ˆæ¡ˆçš„ç¸½é ç®—ã€‚"""
    proj_df = df[df['å°ˆæ¡ˆåç¨±'] == project_name]
    budget = 0
    for _, item in proj_df.groupby('å°ˆæ¡ˆé …ç›®'):
        sel = item[item['é¸å–'] == True]
        budget += sel['ç¸½åƒ¹'].sum() if not sel.empty else item['ç¸½åƒ¹'].min()
    return budget

def calculate_metrics(df, meta):
    """è¨ˆç®—å„€è¡¨æ¿çš„ç¸½é«”æŒ‡æ¨™ã€‚"""
    if df.empty: return 0, 0, 0, 0
    total_projects = len(meta)
    
    budget = 0
    for _, proj in df.groupby('å°ˆæ¡ˆåç¨±'):
        for _, item in proj.groupby('å°ˆæ¡ˆé …ç›®'):
            sel = item[item['é¸å–'] == True]
            budget += sel['ç¸½åƒ¹'].sum() if not sel.empty else item['ç¸½åƒ¹'].min()
            
    risk = (pd.to_datetime(df['é è¨ˆäº¤è²¨æ—¥'], errors='coerce') > pd.to_datetime(df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'], errors='coerce')).sum()
    pending = df[~df['ç‹€æ…‹'].isin(['å·²æ”¶è²¨', 'å–æ¶ˆ'])].shape[0]
    return total_projects, budget, risk, pending


# ==============================================================================
# UI äº‹ä»¶è™•ç†èˆ‡æ•¸æ“šæµæ§åˆ¶
# ==============================================================================

def save_and_rerun(df, meta, msg=""):
    """å„²å­˜è³‡æ–™åˆ° Sheets ä¸¦é‡æ–°æ•´ç† UIã€‚"""
    if write_data_to_sheets(df, meta):
        st.session_state.edited_dataframes = {}
        if msg: 
            st.toast(msg, icon="âœ…")
            time.sleep(1)
        st.rerun()

def handle_master_save():
    """è™•ç†æ‰€æœ‰è¡¨æ ¼ç·¨è¼¯ï¼Œæ›´æ–°ç¸½åƒ¹ä¸¦å¯«å› Sheetsã€‚"""
    if not st.session_state.edited_dataframes:
        st.info("ç„¡è®Šæ›´")
        return

    main_df = st.session_state.data.copy()
    now_str = datetime.now().strftime(DATETIME_FORMAT)
    changes = False
    
    for _, edited_df in st.session_state.edited_dataframes.items():
        if edited_df.empty: continue
        
        for _, new_row in edited_df.iterrows():
            idx = main_df[main_df['ID'] == new_row['ID']].index
            if idx.empty: continue
            idx = idx[0] 
            
            row_changed = False
            # æª¢æŸ¥æ¬„ä½
            check_cols = ['é¸å–', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç‹€æ…‹', 'æ¨™è¨˜åˆªé™¤', 'é è¨ˆäº¤è²¨æ—¥']
            
            for col in check_cols:
                val_main = main_df.loc[idx, col]
                val_new = new_row.get(col)
                
                # ç°¡å–®å­—ä¸²æ¯”è¼ƒï¼Œä¸åšè¤‡é›œçš„æ—¥æœŸç‰©ä»¶è½‰æ›ï¼Œé¿å…éŒ¯èª¤
                if str(val_main) != str(val_new):
                    main_df.loc[idx, col] = val_new
                    row_changed = True
            
            # é‡æ–°è¨ˆç®—ç¸½åƒ¹
            new_total = float(new_row['å–®åƒ¹']) * float(new_row['æ•¸é‡'])
            if main_df.loc[idx, 'ç¸½åƒ¹'] != new_total:
                main_df.loc[idx, 'ç¸½åƒ¹'] = new_total
                row_changed = True
            
            if row_changed:
                main_df.loc[idx, 'æœ€å¾Œä¿®æ”¹æ™‚é–“'] = now_str
                changes = True
                
                # æ›´æ–°å°ˆæ¡ˆ metadata æ™‚é–“
                proj = main_df.loc[idx, 'å°ˆæ¡ˆåç¨±']
                if proj in st.session_state.project_metadata:
                    st.session_state.project_metadata[proj]['last_modified'] = now_str

    if changes:
        st.session_state.data = main_df
        save_and_rerun(st.session_state.data, st.session_state.project_metadata, "âœ… å„²å­˜æˆåŠŸï¼")
    else:
        st.info("â„¹ï¸ æœªåµæ¸¬åˆ°å¯¦è³ªè®Šæ›´ã€‚")

def handle_add_new_quote(latest_arrival, file):
    """è™•ç†æ–°å¢å ±åƒ¹é‚è¼¯ã€‚"""
    proj = st.session_state.quote_project_select
    item = st.session_state.item_name_to_use_final
    if not proj or not item:
        st.error("âŒ è«‹å¡«å¯«å°ˆæ¡ˆåç¨±å’Œæ¡è³¼é …ç›®ã€‚")
        return

    uri = ""
    if file:
        with st.spinner(f"æ­£åœ¨ä¸Šå‚³é™„ä»¶ {file.name}..."):
            uri = upload_attachment_to_gcs(file, st.session_state.next_id) or ""

    now_str = datetime.now().strftime(DATETIME_FORMAT)
    
    # æ±ºå®šé è¨ˆäº¤è²¨æ—¥
    if st.session_state.quote_date_type == "1. æŒ‡å®šæ—¥æœŸ":
        del_date = st.session_state.quote_delivery_date
    else:
        del_date = st.session_state.calculated_delivery_date

    # å»ºç«‹æ–°è³‡æ–™åˆ—
    new_row = {
        'ID': st.session_state.next_id, 'é¸å–': False, 'å°ˆæ¡ˆåç¨±': proj, 'å°ˆæ¡ˆé …ç›®': item,
        'ä¾›æ‡‰å•†': st.session_state.quote_supplier, 'å–®åƒ¹': st.session_state.quote_price,
        'æ•¸é‡': st.session_state.quote_qty, 'ç¸½åƒ¹': st.session_state.quote_price * st.session_state.quote_qty,
        'é è¨ˆäº¤è²¨æ—¥': del_date.strftime(DATE_FORMAT), 
        'ç‹€æ…‹': st.session_state.quote_status,
        'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥': latest_arrival, # é€™è£¡ latest_arrival å·²ç¶“æ˜¯å­—ä¸²
        'æœ€å¾Œä¿®æ”¹æ™‚é–“': now_str, 
        'æ¨™è¨˜åˆªé™¤': False, 'é™„ä»¶URL': uri
    }
    
    st.session_state.next_id += 1
    st.session_state.data = pd.concat([st.session_state.data, pd.DataFrame([new_row])], ignore_index=True)
    st.session_state.project_metadata[proj]['last_modified'] = now_str
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²æˆåŠŸæ–°å¢å ±åƒ¹è‡³ {proj}ï¼")

def handle_project_modification():
    """è™•ç†å°ˆæ¡ˆåç¨±æˆ–äº¤è²¨æ—¥çš„ä¿®æ”¹ã€‚"""
    target_proj = st.session_state.edit_target_project
    new_name = st.session_state.edit_new_name
    new_date = st.session_state.edit_new_date
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)
    
    if not new_name:
        st.error("âŒ å°ˆæ¡ˆåç¨±ä¸èƒ½ç‚ºç©º")
        return
    if target_proj != new_name and new_name in st.session_state.project_metadata:
        st.error(f"âŒ æ–°çš„å°ˆæ¡ˆåç¨± '{new_name}' å·²å­˜åœ¨ã€‚")
        return

    meta = st.session_state.project_metadata.pop(target_proj)
    meta['due_date'] = new_date
    meta['last_modified'] = current_time_str
    st.session_state.project_metadata[new_name] = meta
    
    st.session_state.data.loc[st.session_state.data['å°ˆæ¡ˆåç¨±'] == target_proj, 'å°ˆæ¡ˆåç¨±'] = new_name
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å°ˆæ¡ˆè³‡è¨Šå·²æ›´æ–°ï¼š{new_name}ã€‚")

def handle_delete_project(project_to_delete):
    """æ°¸ä¹…åˆªé™¤æ•´å€‹å°ˆæ¡ˆåŠå…¶æ‰€æœ‰é—œè¯å ±åƒ¹ã€‚"""
    if not project_to_delete: return
    
    if project_to_delete in st.session_state.project_metadata:
        del st.session_state.project_metadata[project_to_delete]
    
    original_count = len(st.session_state.data)
    st.session_state.data = st.session_state.data[st.session_state.data['å°ˆæ¡ˆåç¨±'] != project_to_delete].reset_index(drop=True)
    deleted_count = original_count - len(st.session_state.data)
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å°ˆæ¡ˆ {project_to_delete} åŠå…¶ {deleted_count} ç­†å ±åƒ¹å·²åˆªé™¤ã€‚")

def handle_add_new_project():
    """è™•ç†æ–°å¢å°ˆæ¡ˆè¨­å®šã€‚"""
    project_name = st.session_state.new_proj_name
    project_due_date = st.session_state.new_proj_due_date
    buffer_days = st.session_state.new_proj_buffer_days
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)

    if not project_name:
        st.error("âŒ å°ˆæ¡ˆåç¨±ä¸èƒ½ç‚ºç©ºã€‚")
        return
        
    st.session_state.project_metadata[project_name] = {
        'due_date': project_due_date, 
        'buffer_days': buffer_days,
        'last_modified': current_time_str
    }
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²å„²å­˜å°ˆæ¡ˆè¨­å®šï¼š{project_name}ã€‚")

def trigger_delete_confirmation():
    """è§¸ç™¼ç¢ºèªåˆªé™¤æ¨™è¨˜é …ç›®çš„æµç¨‹ã€‚"""
    temp_df = st.session_state.data.copy()
    
    deletion_updates = []
    for _, edited_df in st.session_state.edited_dataframes.items():
        if not edited_df.empty and 'æ¨™è¨˜åˆªé™¤' in edited_df.columns:
            deletion_updates.append(edited_df[['ID', 'æ¨™è¨˜åˆªé™¤']])
            
    if deletion_updates:
        combined_updates = pd.concat(deletion_updates)
        temp_df.set_index('ID', inplace=True)
        combined_updates.set_index('ID', inplace=True)
        temp_df.update(combined_updates)
        temp_df.reset_index(inplace=True)

    temp_df['æ¨™è¨˜åˆªé™¤'] = temp_df['æ¨™è¨˜åˆªé™¤'].apply(lambda x: True if x == True or str(x).lower() == 'true' else False)
    ids_to_delete = temp_df[temp_df['æ¨™è¨˜åˆªé™¤'] == True]['ID'].tolist()
    
    if not ids_to_delete:
        st.warning("âš ï¸ æ²’æœ‰é …ç›®è¢«æ¨™è¨˜ç‚ºåˆªé™¤ã€‚")
        st.session_state.show_delete_confirm = False
        return

    st.session_state.delete_count = len(ids_to_delete)
    st.session_state.ids_pending_delete = ids_to_delete 
    st.session_state.show_delete_confirm = True
    st.rerun()

def handle_batch_delete_quotes():
    """åŸ·è¡Œæ‰¹æ¬¡åˆªé™¤æ“ä½œã€‚"""
    ids_to_delete = st.session_state.get('ids_pending_delete', [])
    
    if not ids_to_delete:
        st.session_state.show_delete_confirm = False
        st.rerun()
        return
    
    current_data = st.session_state.data
    new_data = current_data[~current_data['ID'].isin(ids_to_delete)].reset_index(drop=True)
    
    st.session_state.data = new_data
    
    st.session_state.show_delete_confirm = False
    st.session_state.delete_count = 0
    st.session_state.ids_pending_delete = []
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²æ°¸ä¹…åˆªé™¤ {len(ids_to_delete)} ç­†è³‡æ–™ã€‚")


# ==============================================================================
# æ‡‰ç”¨ç¨‹å¼é€²å…¥é»èˆ‡é‹è¡Œé‚è¼¯
# ==============================================================================

def run_app():
    """æ‡‰ç”¨ç¨‹å¼çš„ä¸»é‹è¡Œé‚è¼¯ã€‚"""
    st.title(f"ğŸ› ï¸ å°ˆæ¡ˆæ¡è³¼ç®¡ç†å·¥å…· {APP_VERSION}")
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    
    if 'data' not in st.session_state:
        d, m = load_data_from_sheets()
        st.session_state.data = d
        st.session_state.project_metadata = m
    
    if 'next_id' not in st.session_state:
        st.session_state.next_id = st.session_state.data['ID'].max() + 1 if not st.session_state.data.empty and pd.notna(st.session_state.data['ID'].max()) else 1
    if 'edited_dataframes' not in st.session_state: st.session_state.edited_dataframes = {}

    st.session_state.data = calculate_latest_arrival(st.session_state.data, st.session_state.project_metadata)
    
    def get_status_icon(row):
        try:
            proj_date = pd.to_datetime(row['é è¨ˆäº¤è²¨æ—¥']).date()
            latest_date = pd.to_datetime(row['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥']).date()
            if proj_date > latest_date: return "ğŸ”´ è½å¾Œ" 
            elif proj_date <= latest_date: return "âœ… æ­£å¸¸"
            else: return "N/A"
        except: return "N/A"
    
    if not st.session_state.data.empty:
        st.session_state.data['äº¤æœŸç‹€æ…‹'] = st.session_state.data.apply(get_status_icon, axis=1)

    df = st.session_state.data
    
    # ==========================
    #      å´é‚Šæ¬„ (Sidebar UI)
    # ==========================
    with st.sidebar:
        st.button("ğŸšª ç™»å‡ºç³»çµ±", on_click=logout, type="secondary", use_container_width=True)
        st.markdown("---")
        
        # 1. ä¿®æ”¹/åˆªé™¤å°ˆæ¡ˆ
        with st.expander("âœï¸ ä¿®æ”¹/åˆªé™¤å°ˆæ¡ˆè³‡è¨Š", expanded=False):
            all_projects = sorted(list(st.session_state.project_metadata.keys()))
            if all_projects:
                target_proj = st.selectbox("é¸æ“‡ç›®æ¨™å°ˆæ¡ˆ", all_projects, key="edit_target_project")
                operation = st.selectbox("é¸æ“‡æ“ä½œ", ("ä¿®æ”¹å°ˆæ¡ˆè³‡è¨Š", "åˆªé™¤å°ˆæ¡ˆ"), key="project_operation_select")
                st.markdown("---")
                
                current_meta = st.session_state.project_metadata.get(target_proj, {'due_date': datetime.now().date()})
                
                if operation == "ä¿®æ”¹å°ˆæ¡ˆè³‡è¨Š":
                    st.text_input("æ–°å°ˆæ¡ˆåç¨±", value=target_proj, key="edit_new_name")
                    st.date_input("æ–°å°ˆæ¡ˆäº¤è²¨æ—¥", value=current_meta['due_date'], key="edit_new_date")
                    if st.button("ç¢ºèªä¿®æ”¹å°ˆæ¡ˆ", type="primary", use_container_width=True): 
                        handle_project_modification()
                elif operation == "åˆªé™¤å°ˆæ¡ˆ":
                    st.warning(f"âš ï¸ ç¢ºèªæ°¸ä¹…åˆªé™¤å°ˆæ¡ˆ [{target_proj}]ï¼Ÿ")
                    if st.button("ğŸ”¥ ç¢ºèªæ°¸ä¹…åˆªé™¤", type="secondary", use_container_width=True): 
                        handle_delete_project(target_proj)
            else: 
                st.info("ç›®å‰ç„¡å°ˆæ¡ˆè³‡æ–™ã€‚è«‹åœ¨ä¸‹æ–¹æ–°å¢ã€‚")
        
        st.markdown("---")
        
        # 2. æ–°å¢å°ˆæ¡ˆ
        with st.expander("â• æ–°å¢/è¨­å®šå°ˆæ¡ˆæ™‚ç¨‹", expanded=False):
            st.text_input("å°ˆæ¡ˆåç¨±", key="new_proj_name", placeholder="ä¾‹å¦‚: è¾¦å…¬å®¤å‡ç´š")
            project_due_date = st.date_input("å°ˆæ¡ˆäº¤è²¨æ—¥", value=datetime.now().date() + timedelta(days=30), key="new_proj_due_date")
            buffer_days = st.number_input("æ¡è³¼ç·©è¡å¤©æ•¸", min_value=0, value=7, key="new_proj_buffer_days")
            
            calc_date = project_due_date - timedelta(days=int(buffer_days))
            st.info(f"ğŸ“… è¨ˆç®—ä¹‹æœ€æ…¢åˆ°è²¨æ—¥ï¼š{calc_date.strftime(DATE_FORMAT)}")
            
            if st.button("ğŸ’¾ å„²å­˜å°ˆæ¡ˆè¨­å®š", key="btn_save_proj", use_container_width=True): 
                handle_add_new_project()

        st.markdown("---")
        
        # 3. æ–°å¢å ±åƒ¹
        with st.expander("â• æ–°å¢å ±åƒ¹", expanded=True):
            all_projects_for_quote = sorted(list(st.session_state.project_metadata.keys()))
            latest_arrival_date = datetime.now().date()
            
            if not all_projects_for_quote:
                st.warning("è«‹å…ˆåœ¨ä¸Šæ–¹æ–°å¢å°ˆæ¡ˆã€‚")
                project_name = None
            else:
                st.session_state.quote_project_select = st.selectbox("æ­¸å±¬å°ˆæ¡ˆ", all_projects_for_quote, key="quote_project_select_sb")
                current_meta = st.session_state.project_metadata.get(st.session_state.quote_project_select, {'due_date': datetime.now().date(), 'buffer_days': 7})
                latest_arrival_date = current_meta['due_date'] - timedelta(days=int(current_meta['buffer_days']))
                st.caption(f"æ­¤å°ˆæ¡ˆæœ€æ…¢åˆ°è²¨æœŸé™: {latest_arrival_date.strftime(DATE_FORMAT)}")

            unique_items = sorted([x for x in df['å°ˆæ¡ˆé …ç›®'].unique() if x])
            selected_item = st.selectbox("æ¡è³¼é …ç›®", ['ğŸ†• æ–°é …ç›®'] + unique_items, key="quote_item_select")
            
            if selected_item == 'ğŸ†• æ–°é …ç›®':
                item_name_to_use = st.text_input("è¼¸å…¥æ–°é …ç›®åç¨±", key="quote_item_new_input")
            else:
                item_name_to_use = selected_item
            st.session_state.item_name_to_use_final = item_name_to_use
            
            col_sup, col_pr = st.columns(2)
            st.session_state.quote_supplier = col_sup.text_input("ä¾›æ‡‰å•†", key="quote_supplier_input")
            st.session_state.quote_price = col_pr.number_input("å–®åƒ¹", min_value=0.0, key="quote_price_input")
            st.session_state.quote_qty = st.number_input("æ•¸é‡", min_value=1, value=1, key="quote_qty_input")
            
            st.markdown("---")
            st.markdown("ğŸ“† **é è¨ˆäº¤è²¨æ—¥è¨­å®š**", unsafe_allow_html=True)
            date_input_type = st.radio("è¼¸å…¥æ–¹å¼", ("1. æŒ‡å®šæ—¥æœŸ", "2. è‡ªç„¶æ—¥æ•¸", "3. å·¥ä½œæ—¥æ•¸"), key="quote_date_type", horizontal=True)
            
            today = datetime.now().date()
            if date_input_type == "1. æŒ‡å®šæ—¥æœŸ": 
                st.session_state.quote_delivery_date = st.date_input("é¸æ“‡æ—¥æœŸ", today, key="quote_delivery_date_input") 
            elif date_input_type == "2. è‡ªç„¶æ—¥æ•¸": 
                num_days = st.number_input("å¹¾å¤©å¾Œäº¤è²¨?", 1, value=7, key="quote_num_days_input")
                st.session_state.calculated_delivery_date = today + timedelta(days=int(num_days))
                st.info(f"è¨ˆç®—çµæœï¼š{st.session_state.calculated_delivery_date.strftime(DATE_FORMAT)}")
            elif date_input_type == "3. å·¥ä½œæ—¥æ•¸": 
                num_b_days = st.number_input("å¹¾å€‹å·¥ä½œå¤©?", 1, value=5, key="quote_num_b_days_input")
                st.session_state.calculated_delivery_date = add_business_days(today, int(num_b_days))
                st.info(f"è¨ˆç®—çµæœï¼š{st.session_state.calculated_delivery_date.strftime(DATE_FORMAT)}")
            
            st.session_state.quote_status = st.selectbox("åˆå§‹ç‹€æ…‹", STATUS_OPTIONS, key="quote_status_select")
            
            st.markdown("ğŸ“ **é™„ä»¶ä¸Šå‚³**", unsafe_allow_html=True)
            uploaded_file = st.file_uploader("æ”¯æ´ PDF/åœ–ç‰‡", type=['pdf', 'jpg', 'jpeg', 'png'], key="new_quote_file_uploader")

            if st.button("ğŸ“¥ æ–°å¢è³‡æ–™", key="btn_add_quote", type="primary", use_container_width=True):
                handle_add_new_quote(latest_arrival_date, uploaded_file)


    # ==========================
    #      ä¸»ç•«é¢ (Main UI)
    # ==========================
    
    n, b, r, p = calculate_metrics(df, st.session_state.project_metadata)
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("å°ˆæ¡ˆæ•¸", n)
    c2.metric("ç¸½é ç®—", f"${b:,.0f}")
    c3.metric("é¢¨éšªé …", r)
    c4.metric("å¾…è™•ç†", p)
    
    st.markdown("---")
    
    col_save, col_delete = st.columns([0.8, 0.2])
    with col_save:
        if st.button("ğŸ’¾ å„²å­˜æ‰€æœ‰è¡¨æ ¼ä¿®æ”¹ (ä¸¦é‡æ–°è¨ˆç®—ç¸½åƒ¹)", type="primary"): 
            handle_master_save()
    with col_delete:
        if st.button("ğŸ—‘ï¸ åˆªé™¤å·²æ¨™è¨˜é …ç›®", type="secondary"):
            trigger_delete_confirmation()

    if st.session_state.get('show_delete_confirm'):
        st.error(f"âš ï¸ ç¢ºèªæ°¸ä¹…åˆªé™¤ {st.session_state.delete_count} ç­†è³‡æ–™ï¼Ÿæ­¤æ“ä½œä¸å¯å¾©åŸï¼")
        cy, cn, _ = st.columns([0.15, 0.15, 0.7])
        with cy: 
            if st.button("âœ… ç¢ºèªåˆªé™¤", key="confirm_delete_yes", type="primary"): handle_batch_delete_quotes()
        with cn: 
            if st.button("âŒ å–æ¶ˆ", key="confirm_delete_no"): st.session_state.show_delete_confirm = False
    
    st.markdown("---")

    if df.empty:
        st.info("ğŸ‘‹ æ­¡è¿ä½¿ç”¨ï¼ç›®å‰æ²’æœ‰è³‡æ–™ï¼Œè«‹å¾å·¦å´å´é‚Šæ¬„æ–°å¢å°ˆæ¡ˆèˆ‡å ±åƒ¹ã€‚")
        
    for proj_name, proj_data in df.groupby('å°ˆæ¡ˆåç¨±'):
        meta = st.session_state.project_metadata.get(proj_name, {})
        
        st.subheader(f"ğŸ’¼ {proj_name} | äº¤æœŸ: {meta.get('due_date')}")
        
        with st.expander("å±•é–‹æ˜ç´°", expanded=True):
            for item_name, item_data in proj_data.groupby('å°ˆæ¡ˆé …ç›®'):
                st.markdown(f"**ğŸ“¦ {item_name}**")
                
                display = item_data.copy()
                display['é™„ä»¶é€£çµ'] = None
                for idx, row in display.iterrows():
                    if row.get('é™„ä»¶URL'):
                        url = generate_signed_url_cached(row['é™„ä»¶URL'])
                        if url: display.at[idx, 'é™„ä»¶é€£çµ'] = url
                
                # Column Config - å›å¾©æœ€åŸå§‹è¨­å®šï¼Œå–æ¶ˆ DateColumn ä»¥è§£æ±ºéŒ¯èª¤
                edited = st.data_editor(
                    display[['ID', 'é¸å–', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 
                             'é è¨ˆäº¤è²¨æ—¥', 'äº¤æœŸç‹€æ…‹', 'ç‹€æ…‹', 'é™„ä»¶é€£çµ', 'æœ€å¾Œä¿®æ”¹æ™‚é–“', 'æ¨™è¨˜åˆªé™¤', 'é™„ä»¶URL']],
                    column_config={
                        "ID": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                        "é¸å–": st.column_config.CheckboxColumn("é¸", width="small"),
                        "ç¸½åƒ¹": st.column_config.NumberColumn(format="$%d", disabled=True),
                        # å–æ¶ˆ DateColumn è¨­å®šï¼Œé¿å…å­—ä¸²/æ—¥æœŸå‹åˆ¥è¡çª
                        "é è¨ˆäº¤è²¨æ—¥": st.column_config.TextColumn("é è¨ˆäº¤è²¨æ—¥", help="æ ¼å¼: YYYY-MM-DD"),
                        
                        "äº¤æœŸç‹€æ…‹": st.column_config.TextColumn("æœŸé™åˆ¤å®š", disabled=True, width="small"), 
                        "æœ€å¾Œä¿®æ”¹æ™‚é–“": st.column_config.TextColumn("æœ€å¾Œä¿®æ”¹", disabled=True, width="medium"), 
                        "é™„ä»¶é€£çµ": st.column_config.LinkColumn("é™„ä»¶", display_text="ğŸ“„ é–‹å•Ÿ", width="small"),
                        "æ¨™è¨˜åˆªé™¤": st.column_config.CheckboxColumn("åˆªé™¤?", width="small"),
                        # æ¢å¾©é¡¯ç¤ºç³»çµ±è·¯å¾‘ (V2.2.5 é è¨­é¡¯ç¤º)
                        "é™„ä»¶URL": st.column_config.TextColumn("ç³»çµ±è·¯å¾‘ (gs://)", disabled=True) 
                    },
                    hide_index=True,
                    key=f"ed_{proj_name}_{item_name}",
                    num_rows="dynamic"
                )
                st.session_state.edited_dataframes[item_name] = edited
            st.markdown("<br>", unsafe_allow_html=True)

def main():
    login_form()
    if st.session_state.authenticated: run_app()

if __name__ == "__main__":
    main()
