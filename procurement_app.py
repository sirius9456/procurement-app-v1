import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO
import os 
import json
import gspread
import logging
import time

# å¼•å…¥ Google Cloud Storage åº«
from google.cloud import storage

# ç¢ºä¿ openpyxl åº«å·²å®‰è£ (pip install openpyxl)

# --- æ‡‰ç”¨ç¨‹å¼è¨­å®šèˆ‡å¸¸æ•¸ ---
APP_VERSION = "v2.2.5 (Production + Hyperlink Fix)"
STATUS_OPTIONS = ["å¾…æ¡è³¼", "å·²ä¸‹å–®", "å·²æ”¶è²¨", "å–æ¶ˆ"]
DATE_FORMAT = "%Y-%m-%d"
DATETIME_FORMAT = "%Y-%m-%d %H:%M:%S"

# --- Google Cloud Storage é…ç½® ---
# è«‹æ›¿æ›ç‚ºæ‚¨çš„å„²å­˜æ¡¶åç¨±
GCS_BUCKET_NAME = "procurement-attachments-bucket"
GCS_ATTACHMENT_FOLDER = "attachments"

# --- æ—¥èªŒé…ç½® ---
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- æ•¸æ“šæºé…ç½® (ç’°å¢ƒè®Šæ•¸å„ªå…ˆ) ---
# å°‡æ†‘è­‰è·¯å¾‘è¨­ç‚ºå…¨åŸŸè®Šæ•¸ï¼Œä¾› Gspread å’Œ GCS å…±ç”¨
if "GCE_SHEET_URL" in os.environ:
    SHEET_URL = os.environ["GCE_SHEET_URL"]
    try:
        GSHEETS_CREDENTIALS = os.environ["GSHEETS_CREDENTIALS_PATH"] 
    except KeyError:
        logger.error("GSHEETS_CREDENTIALS_PATH is missing in environment variables.")
        st.error("âŒ åš´é‡éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GSHEETS_CREDENTIALS_PATH ç’°å¢ƒè®Šæ•¸ã€‚è«‹æª¢æŸ¥æœå‹™é…ç½®ã€‚")
        GSHEETS_CREDENTIALS = None 
else:
    # æœ¬åœ°é–‹ç™¼æˆ– Streamlit Cloud å‚™ç”¨
    try:
        SHEET_URL = st.secrets["app_config"]["sheet_url"]
        GSHEETS_CREDENTIALS = None # æœ¬åœ°é€šå¸¸ä¾è³´é è¨­æ†‘è­‰æˆ– secrets ä¸­çš„ json å…§å®¹
    except KeyError:
        SHEET_URL = None
        GSHEETS_CREDENTIALS = None
        
DATA_SHEET_NAME = "æ¡è³¼ç¸½è¡¨"
METADATA_SHEET_NAME = "å°ˆæ¡ˆè¨­å®š"


# --- Streamlit é é¢è¨­å®š ---
st.set_page_config(
    page_title=f"å°ˆæ¡ˆæ¡è³¼å°å¹«æ‰‹ {APP_VERSION}", 
    page_icon="ğŸ› ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS æ¨£å¼å„ªåŒ– ---
CUSTOM_CSS = """
<style>
    /* å…¨åŸŸå­—é«”èˆ‡é–“è·èª¿æ•´ */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Expander æ¨£å¼å„ªåŒ– */
    .streamlit-expanderContent { 
        padding-left: 1rem !important; 
        padding-right: 1rem !important; 
        padding-bottom: 1rem !important; 
        border-top: 1px solid #444;
    }
    
    /* è‡ªå®šç¾©æ¨™é¡Œæ¨£å¼ */
    .project-header { 
        font-size: 20px !important; 
        font-weight: bold !important; 
        color: #FAFAFA; 
        font-family: 'Source Sans Pro', sans-serif;
    }
    .item-header { 
        font-size: 16px !important; 
        font-weight: 600 !important; 
        color: #E0E0E0; 
        margin-top: 10px;
        margin-bottom: 5px;
        display: block;
    }
    .meta-info { 
        font-size: 14px !important; 
        color: #9E9E9E; 
        font-weight: normal; 
    }
    
    /* è¡¨å–®å…ƒä»¶æ¨£å¼è¦†è“‹ (Dark Mode é©é…) */
    div[data-baseweb="select"] > div, 
    div[data-baseweb="base-input"] > input, 
    div[data-baseweb="input"] > div { 
        background-color: #262730 !important; 
        color: white !important; 
        -webkit-text-fill-color: white !important; 
    }
    div[data-baseweb="popover"], 
    div[data-baseweb="menu"] { 
        background-color: #262730 !important; 
    }
    div[data-baseweb="option"] { 
        color: white !important; 
    }
    
    /* å„€è¡¨æ¿æŒ‡æ¨™å¡ç‰‡ */
    .metric-box { 
        padding: 15px 20px; 
        border-radius: 8px; 
        margin-bottom: 15px; 
        background-color: #262730; 
        text-align: center; 
        box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        border: 1px solid #444;
    }
    .metric-title { 
        font-size: 14px; 
        color: #B0B0B0; 
        margin-bottom: 8px; 
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    .metric-value { 
        font-size: 28px; 
        font-weight: bold; 
        color: #FFFFFF;
    }
    
    /* æŒ‰éˆ•æ¨£å¼å¾®èª¿ */
    button[kind="secondary"] {
        border: 1px solid #555 !important;
    }
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
"""

# --- èº«ä»½é©—è­‰èˆ‡å®‰å…¨å‡½å¼ ---

def logout():
    """ç™»å‡ºå‡½å¼ï¼šæ¸…é™¤é©—è­‰ç‹€æ…‹ä¸¦é‡æ–°é‹è¡Œæ‡‰ç”¨ç¨‹å¼ã€‚"""
    st.session_state["authenticated"] = False
    # æ¸…é™¤ç›¸é—œ Session State
    keys_to_clear = ['data', 'project_metadata', 'edited_dataframes']
    for key in keys_to_clear:
        if key in st.session_state:
            del st.session_state[key]
    st.rerun()

def login_form():
    """æ¸²æŸ“ç™»å…¥è¡¨å–®ä¸¦è™•ç†å¯†ç¢¼é©—è­‰ã€‚"""
    # å¾ systemd ç’°å¢ƒè®Šæ•¸ä¸­è®€å–å¸³å¯†ï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨é è¨­å€¼
    DEFAULT_USERNAME = os.environ.get("AUTH_USERNAME", "dev_user")
    DEFAULT_PASSWORD = os.environ.get("AUTH_PASSWORD", "dev_pwd")
    
    credentials = {"username": DEFAULT_USERNAME, "password": DEFAULT_PASSWORD}

    if "authenticated" not in st.session_state:
        st.session_state["authenticated"] = False
        
    if st.session_state["authenticated"]:
        return # å·²é©—è­‰ï¼Œè·³éè¡¨å–®

    st.markdown("<br><br><br>", unsafe_allow_html=True)
    col_empty_l, col_center, col_empty_r = st.columns([1, 2, 1])
    
    with col_center:
        with st.container(border=True):
            st.title("ğŸ” ç³»çµ±ç™»å…¥")
            st.markdown("è«‹è¼¸å…¥æ‚¨çš„æ†‘è­‰ä»¥å­˜å–å°ˆæ¡ˆæ¡è³¼ç®¡ç†ç³»çµ±ã€‚")
            st.markdown("---")
            
            username = st.text_input("ç”¨æˆ¶å", key="login_username", value=credentials["username"], disabled=True)
            password = st.text_input("å¯†ç¢¼", type="password", key="login_password")
            
            col_login_btn, _ = st.columns([1, 2])
            with col_login_btn:
                if st.button("ç™»å…¥", type="primary", use_container_width=True):
                    if username.strip() == credentials["username"].strip() and password == credentials["password"]:
                        st.session_state["authenticated"] = True
                        st.toast("âœ… ç™»å…¥æˆåŠŸï¼æ­£åœ¨è¼‰å…¥æ•¸æ“š...", icon="ğŸš€")
                        time.sleep(0.5)
                        st.rerun()
                    else:
                        st.error("âŒ ç”¨æˆ¶åæˆ–å¯†ç¢¼éŒ¯èª¤ï¼Œè«‹é‡è©¦ã€‚")
    st.stop() 


# --- GCS æª”æ¡ˆæœå‹™å‡½å¼ (V2.2.5 å®Œæ•´ç‰ˆ) ---

def get_storage_client():
    """
    ç²å– GCS å®¢æˆ¶ç«¯ã€‚
    å„ªå…ˆä½¿ç”¨ JSON é‡‘é‘°æª”æ¡ˆä»¥æ”¯æ´ generate_signed_url åŠŸèƒ½ã€‚
    """
    if GSHEETS_CREDENTIALS and os.path.exists(GSHEETS_CREDENTIALS):
        try:
            # æ˜ç¢ºä½¿ç”¨ Service Account JSONï¼Œç¢ºä¿æœ‰ Private Key
            return storage.Client.from_service_account_json(GSHEETS_CREDENTIALS)
        except Exception as e:
            logger.error(f"ç„¡æ³•å¾ JSON å»ºç«‹ GCS Client: {e}")
            return storage.Client() # é™ç´šå˜—è©¦
    else:
        return storage.Client() # ä½¿ç”¨ç’°å¢ƒé è¨­æ†‘è­‰

def upload_attachment_to_gcs(file_obj, next_id):
    """
    å°‡ä¸Šå‚³çš„æª”æ¡ˆå„²å­˜è‡³ Google Cloud Storageã€‚
    
    Args:
        file_obj: Streamlit UploadedFile ç‰©ä»¶
        next_id: ä¸‹ä¸€å€‹å ±åƒ¹çš„ IDï¼Œç”¨æ–¼æª”æ¡ˆå‘½å
        
    Returns:
        str: GCS URI (gs://...) æˆ– None (å¦‚æœå¤±æ•—)
    """
    if file_obj is None:
        return None
        
    try:
        storage_client = get_storage_client()
        bucket = storage_client.bucket(GCS_BUCKET_NAME)
        
        # å»ºç«‹æª”æ¡ˆåç¨±ï¼šattachments/{ID}_{Timestamp}{Extension}
        file_extension = os.path.splitext(file_obj.name)[1]
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        blob_name = f"{GCS_ATTACHMENT_FOLDER}/{next_id}_{timestamp}{file_extension}"
        
        blob = bucket.blob(blob_name)
        
        # é‡ç½®æª”æ¡ˆæŒ‡æ¨™ä¸¦ä¸Šå‚³
        file_obj.seek(0)
        blob.upload_from_file(
            file_obj, 
            content_type=file_obj.type
        )
        
        gcs_uri = f"gs://{GCS_BUCKET_NAME}/{blob_name}"
        logger.info(f"æª”æ¡ˆä¸Šå‚³æˆåŠŸ: {gcs_uri}")
        return gcs_uri

    except Exception as e:
        logger.exception("GCS ä¸Šå‚³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤")
        st.error(f"âŒ é™„ä»¶ä¸Šå‚³å¤±æ•—ã€‚è«‹æª¢æŸ¥ GCS æ¬Šé™é…ç½®æˆ– Bucket åç¨±ã€‚éŒ¯èª¤: {e}")
        return None

@st.cache_data(ttl=3600, show_spinner=False)
def generate_signed_url_cached(gcs_uri):
    """
    ç‚ºç§æœ‰ GCS ç‰©ä»¶ç”Ÿæˆå¸¶æœ‰ç°½ç« çš„è‡¨æ™‚ URL (Signed URL)ã€‚
    ä½¿ç”¨ cache é¿å…é‡è¤‡è«‹æ±‚ APIï¼Œç°½ç« æœ‰æ•ˆæœŸè¨­ç‚º 60 åˆ†é˜ã€‚
    """
    if not gcs_uri or not isinstance(gcs_uri, str):
        return None
        
    # å¦‚æœå·²ç¶“æ˜¯ HTTP é€£çµï¼Œç›´æ¥è¿”å›
    if gcs_uri.startswith("http://") or gcs_uri.startswith("https://"):
        return gcs_uri
        
    # å¦‚æœä¸æ˜¯ gs:// æ ¼å¼ï¼Œè¦–ç‚ºç„¡æ•ˆ
    if not gcs_uri.startswith("gs://"):
        return None

    try:
        # è§£æ gs://bucket_name/blob_name
        # gs:// éƒ¨åˆ†é•·åº¦ç‚º 5
        path_part = gcs_uri[5:]
        parts = path_part.split('/', 1)
        
        if len(parts) != 2:
            return None
            
        bucket_name = parts[0]
        blob_name = parts[1]
        
        storage_client = get_storage_client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_name)
        
        # ç”Ÿæˆ V4 ç°½ç« 
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(minutes=60), # 1å°æ™‚æœ‰æ•ˆ
            method="GET"
        )
        return url
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆ Signed URL å¤±æ•— ({gcs_uri}): {e}")
        # ä¸åœ¨å‰ç«¯é¡¯ç¤ºéŒ¯èª¤ï¼Œé¿å…å¹²æ“¾ä½¿ç”¨è€…é«”é©—ï¼Œå›å‚³ None è®“ UI é¡¯ç¤ºç©ºç™½
        return None


# --- æ•¸æ“šè®€å–èˆ‡å¯«å…¥å‡½å¼ (Gspread å®Œæ•´å¯¦ä½œ) ---

@st.cache_data(ttl=600, show_spinner="æ­£åœ¨åŒæ­¥ Google Sheets æ•¸æ“š...")
def load_data_from_sheets():
    """
    å¾ Google Sheets è®€å–æ¡è³¼æ•¸æ“šèˆ‡å°ˆæ¡ˆè¨­å®šã€‚
    åŒ…å«å®Œæ•´çš„æ¬„ä½æª¢æŸ¥èˆ‡è³‡æ–™é¡å‹è½‰æ›ã€‚
    """
    if not SHEET_URL:
        st.warning("âš ï¸ Google Sheets URL å°šæœªé…ç½®ï¼Œå°‡ä½¿ç”¨ç©ºç™½æ•¸æ“šæ¨¡å¼ã€‚")
        empty_data = pd.DataFrame(columns=['ID', 'é¸å–', 'å°ˆæ¡ˆåç¨±', 'å°ˆæ¡ˆé …ç›®', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 'é è¨ˆäº¤è²¨æ—¥', 'ç‹€æ…‹', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥', 'æ¨™è¨˜åˆªé™¤', 'é™„ä»¶URL'])
        return empty_data, {}

    try:
        # é€£ç·š
        if GSHEETS_CREDENTIALS:
            gc = gspread.service_account(filename=GSHEETS_CREDENTIALS)
        else:
            # å˜—è©¦ä½¿ç”¨é è¨­æ†‘è­‰ (åœ¨ Streamlit Cloud å¯èƒ½éœ€è¦ secrets)
            gc = gspread.service_account()
            
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 1. è®€å–æ¡è³¼ç¸½è¡¨ (Data) ---
        try:
            data_ws = sh.worksheet(DATA_SHEET_NAME)
        except gspread.exceptions.WorksheetNotFound:
            st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨: {DATA_SHEET_NAME}")
            raise

        data_records = data_ws.get_all_records()
        data_df = pd.DataFrame(data_records)

        # æ¬„ä½å®Œæ•´æ€§æª¢æŸ¥èˆ‡è£œå…¨
        required_columns = ['ID', 'é¸å–', 'å°ˆæ¡ˆåç¨±', 'å°ˆæ¡ˆé …ç›®', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 'é è¨ˆäº¤è²¨æ—¥', 'ç‹€æ…‹', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥']
        for col in required_columns:
            if col not in data_df.columns:
                data_df[col] = "" # è£œå…¨ç¼ºå¤±æ¬„ä½
        
        if 'æ¨™è¨˜åˆªé™¤' not in data_df.columns:
            data_df['æ¨™è¨˜åˆªé™¤'] = False
            
        if 'é™„ä»¶URL' not in data_df.columns:
            data_df['é™„ä»¶URL'] = ""
            
        # åš´æ ¼çš„è³‡æ–™é¡å‹è½‰æ›
        data_df['ID'] = pd.to_numeric(data_df['ID'], errors='coerce').astype('Int64')
        data_df['å–®åƒ¹'] = pd.to_numeric(data_df['å–®åƒ¹'], errors='coerce').fillna(0).astype('float')
        data_df['æ•¸é‡'] = pd.to_numeric(data_df['æ•¸é‡'], errors='coerce').fillna(1).astype('Int64')
        data_df['ç¸½åƒ¹'] = pd.to_numeric(data_df['ç¸½åƒ¹'], errors='coerce').fillna(0).astype('float')
        
        # å¸ƒæ—å€¼è™•ç† (Sheets æœ‰æ™‚æœƒå›å‚³ TRUE/FALSE å­—ä¸²)
        data_df['é¸å–'] = data_df['é¸å–'].apply(lambda x: True if str(x).upper() == 'TRUE' else False)
        data_df['æ¨™è¨˜åˆªé™¤'] = data_df['æ¨™è¨˜åˆªé™¤'].apply(lambda x: True if str(x).upper() == 'TRUE' else False)

        # --- 2. è®€å–å°ˆæ¡ˆè¨­å®š (Metadata) ---
        try:
            metadata_ws = sh.worksheet(METADATA_SHEET_NAME)
            metadata_records = metadata_ws.get_all_records()
        except gspread.exceptions.WorksheetNotFound:
            st.warning(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨: {METADATA_SHEET_NAME}ï¼Œå°‡ä½¿ç”¨é è¨­è¨­å®šã€‚")
            metadata_records = []
        
        project_metadata = {}
        if metadata_records:
            for row in metadata_records:
                proj_name = row.get('å°ˆæ¡ˆåç¨±')
                if not proj_name: continue
                
                try: 
                    due_date = pd.to_datetime(str(row.get('å°ˆæ¡ˆäº¤è²¨æ—¥'))).date()
                except (ValueError, TypeError): 
                    due_date = datetime.now().date()
                
                try:
                    buffer_days = int(row.get('ç·©è¡å¤©æ•¸', 7))
                except (ValueError, TypeError):
                    buffer_days = 7
                    
                project_metadata[proj_name] = {
                    'due_date': due_date,
                    'buffer_days': buffer_days,
                    'last_modified': str(row.get('æœ€å¾Œä¿®æ”¹', ''))
                }

        logger.info(f"æˆåŠŸè¼‰å…¥ {len(data_df)} ç­†è³‡æ–™ï¼Œ{len(project_metadata)} å€‹å°ˆæ¡ˆè¨­å®šã€‚")
        st.toast("âœ… æ•¸æ“šå·²å¾ Google Sheets æ›´æ–°", icon="â˜ï¸")
        return data_df, project_metadata

    except Exception as e:
        logger.exception("Google Sheets æ•¸æ“šè¼‰å…¥å¤±æ•—") 
        st.error(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼è«‹æª¢æŸ¥æ¬Šé™æˆ–ç¶²è·¯é€£ç·šã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        st.session_state.data_load_failed = True
        return pd.DataFrame(), {}


def write_data_to_sheets(df_to_write, metadata_to_write):
    """
    å°‡ DataFrame å’Œ Metadata å¯«å› Google Sheetsã€‚
    åŸ·è¡Œåš´æ ¼çš„æ¬„ä½éæ¿¾ï¼Œé¿å…å¯«å…¥å‰ç«¯è¼”åŠ©æ¬„ä½ (å¦‚: LinkColumn)ã€‚
    """
    if st.session_state.get('data_load_failed', False) or not SHEET_URL:
        st.warning("ç”±æ–¼è¼‰å…¥å¤±æ•—æˆ–æœªé…ç½® URLï¼Œå¯«å…¥æ“ä½œå·²æš«åœä»¥ä¿è­·æ•¸æ“šã€‚")
        return False
        
    try:
        gc = gspread.service_account(filename=GSHEETS_CREDENTIALS)
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 1. å¯«å…¥æ¡è³¼ç¸½è¡¨ ---
        # ç§»é™¤å‰ç«¯é¡¯ç¤ºç”¨çš„è¼”åŠ©æ¬„ä½
        columns_to_exclude = ['æ¨™è¨˜åˆªé™¤', 'äº¤æœŸé¡¯ç¤º', 'é™„ä»¶é€£çµ']
        df_export = df_to_write.drop(columns=columns_to_exclude, errors='ignore')
        
        # è™•ç†æ—¥æœŸç‰©ä»¶è½‰å­—ä¸² (é¿å… JSON åºåˆ—åŒ–éŒ¯èª¤)
        for col in df_export.columns:
            if pd.api.types.is_datetime64_any_dtype(df_export[col]):
                df_export[col] = df_export[col].dt.strftime(DATE_FORMAT)
        
        # å¡«å…… NaN ç‚ºç©ºå­—ä¸²
        df_export = df_export.fillna("")
        
        data_ws = sh.worksheet(DATA_SHEET_NAME)
        data_ws.clear()
        # å¯«å…¥ Header å’Œ Data
        data_ws.update([df_export.columns.values.tolist()] + df_export.values.tolist())
        
        # --- 2. å¯«å…¥å°ˆæ¡ˆè¨­å®š ---
        metadata_list = []
        for name, data in metadata_to_write.items():
            metadata_list.append({
                'å°ˆæ¡ˆåç¨±': name, 
                'å°ˆæ¡ˆäº¤è²¨æ—¥': data['due_date'].strftime(DATE_FORMAT),
                'ç·©è¡å¤©æ•¸': data['buffer_days'], 
                'æœ€å¾Œä¿®æ”¹': data['last_modified']
            })
            
        metadata_df = pd.DataFrame(metadata_list)
        metadata_ws = sh.worksheet(METADATA_SHEET_NAME)
        metadata_ws.clear()
        if not metadata_df.empty:
            metadata_ws.update([metadata_df.columns.values.tolist()] + metadata_df.values.tolist())
        
        # æ¸…é™¤å¿«å–ï¼Œç¢ºä¿ä¸‹æ¬¡è®€å–æœ€æ–°æ•¸æ“š
        st.cache_data.clear() 
        logger.info("æ•¸æ“šå¯«å…¥æˆåŠŸã€‚")
        return True
        
    except Exception as e:
        logger.exception("Google Sheets å¯«å…¥å¤±æ•—")
        st.error(f"âŒ å¯«å…¥ Google Sheets å¤±æ•—ï¼è«‹ç¨å¾Œé‡è©¦ã€‚éŒ¯èª¤: {e}")
        return False


# --- å•†æ¥­é‚è¼¯èˆ‡è¨ˆç®—å‡½å¼ ---

def add_business_days(start_date, num_days):
    """è¨ˆç®—å·¥ä½œæ—¥ (è·³éé€±æœ«)ã€‚"""
    current_date = start_date
    days_added = 0
    while days_added < num_days:
        current_date += timedelta(days=1)
        if current_date.weekday() < 5: # 0-4 æ˜¯é€±ä¸€åˆ°é€±äº”
            days_added += 1
    return current_date

@st.cache_data
def convert_df_to_excel(df):
    """è½‰æ› DataFrame ç‚º Excel æ ¼å¼ä¾›ä¸‹è¼‰ã€‚"""
    # ç§»é™¤å…§éƒ¨æ¬„ä½
    df_export = df.drop(columns=['æ¨™è¨˜åˆªé™¤', 'äº¤æœŸé¡¯ç¤º', 'é™„ä»¶é€£çµ'], errors='ignore')
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_export.to_excel(writer, index=False, sheet_name='æ¡è³¼å ±åƒ¹ç¸½è¡¨')
    return output.getvalue()

@st.cache_data(show_spinner=False)
def calculate_dashboard_metrics(df_state, project_metadata_state):
    """è¨ˆç®—å„€è¡¨æ¿é¡¯ç¤ºçš„ KPI æŒ‡æ¨™ã€‚"""
    total_projects = len(project_metadata_state)
    total_budget = 0
    risk_items = 0
    df = df_state.copy()
    
    if df.empty:
        return 0, 0, 0, 0

    # è¨ˆç®—é ç®—é‚è¼¯ï¼šè‹¥æœ‰å‹¾é¸å‰‡åŠ ç¸½å‹¾é¸é …ç›®ï¼Œè‹¥ç„¡å‰‡å–æœ€å°å€¼(é ä¼°)
    for _, proj_data in df.groupby('å°ˆæ¡ˆåç¨±'):
        for _, item_df in proj_data.groupby('å°ˆæ¡ˆé …ç›®'):
            selected_rows = item_df[item_df['é¸å–'] == True]
            if not selected_rows.empty:
                total_budget += selected_rows['ç¸½åƒ¹'].sum()
            elif not item_df.empty:
                # è‹¥å°šæœªé¸å®šå» å•†ï¼Œæš«æ™‚åŠ ç¸½è©²é …ç›®ä¸­æœ€ä½åƒ¹çš„å ±åƒ¹
                total_budget += item_df['ç¸½åƒ¹'].min()
    
    # è¨ˆç®—äº¤æœŸé¢¨éšª
    temp_df = df.copy() 
    temp_df['é è¨ˆäº¤è²¨æ—¥_dt'] = pd.to_datetime(temp_df['é è¨ˆäº¤è²¨æ—¥'], errors='coerce')
    temp_df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_dt'] = pd.to_datetime(temp_df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'], errors='coerce')
    
    # é¢¨éšªå®šç¾©ï¼šé è¨ˆäº¤è²¨æ—¥ > æœ€æ…¢åˆ°è²¨æ—¥
    risk_items = (temp_df['é è¨ˆäº¤è²¨æ—¥_dt'] > temp_df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_dt']).sum()

    # å¾…è™•ç†å ±åƒ¹
    pending_quotes = df[~df['ç‹€æ…‹'].isin(['å·²æ”¶è²¨', 'å–æ¶ˆ'])].shape[0]

    return total_projects, total_budget, risk_items, pending_quotes

def calculate_project_budget(df, project_name):
    """è¨ˆç®—å–®ä¸€å°ˆæ¡ˆçš„é ç®—ã€‚"""
    proj_df = df[df['å°ˆæ¡ˆåç¨±'] == project_name]
    total_budget = 0
    for _, item_df in proj_df.groupby('å°ˆæ¡ˆé …ç›®'):
        selected_rows = item_df[item_df['é¸å–'] == True]
        if not selected_rows.empty:
            total_budget += selected_rows['ç¸½åƒ¹'].sum()
        else:
            if not item_df.empty:
                total_budget += item_df['ç¸½åƒ¹'].min()
    return total_budget

@st.cache_data(show_spinner=False)
def calculate_latest_arrival_dates(df, metadata):
    """
    è‡ªå‹•è¨ˆç®—æœ€æ…¢åˆ°è²¨æ—¥ã€‚
    å…¬å¼ï¼šå°ˆæ¡ˆäº¤è²¨æ—¥ - ç·©è¡å¤©æ•¸
    """
    if df.empty or not metadata:
        return df

    # å°‡ metadata è½‰ç‚º DataFrame ä»¥ä¾¿ merge
    metadata_df = pd.DataFrame.from_dict(metadata, orient='index')
    metadata_df = metadata_df.reset_index().rename(columns={'index': 'å°ˆæ¡ˆåç¨±'})
    metadata_df['due_date'] = metadata_df['due_date'].apply(lambda x: pd.to_datetime(x).date())
    metadata_df['buffer_days'] = metadata_df['buffer_days'].astype(int)

    # åˆä½µè³‡è¨Š
    df = pd.merge(df, metadata_df[['å°ˆæ¡ˆåç¨±', 'due_date', 'buffer_days']], on='å°ˆæ¡ˆåç¨±', how='left')
    
    # è¨ˆç®—
    df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_TEMP'] = (
        pd.to_datetime(df['due_date']) - 
        df['buffer_days'].apply(lambda x: timedelta(days=x))
    )
    df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'] = df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_TEMP'].dt.strftime(DATE_FORMAT)
    
    # æ¸…ç†æš«å­˜æ¬„ä½
    df = df.drop(columns=['due_date', 'buffer_days', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_TEMP'], errors='ignore')
    return df


# --- UI äº‹ä»¶è™•ç†å‡½å¼ (å®Œæ•´é‚è¼¯) ---

def save_and_rerun(df_to_save, metadata_to_save, success_message=""):
    """å„²å­˜è³‡æ–™ä¸¦é‡æ–°æ•´ç†é é¢ã€‚"""
    if write_data_to_sheets(df_to_save, metadata_to_save):
        st.session_state.edited_dataframes = {} # æ¸…ç©ºç·¨è¼¯ç‹€æ…‹
        if success_message:
            st.success(success_message)
            time.sleep(1) # çµ¦ä½¿ç”¨è€…ä¸€é»æ™‚é–“çœ‹è¨Šæ¯
        st.rerun()

def handle_master_save():
    """
    è™•ç†ä¸»è¡¨æ ¼çš„ç·¨è¼¯å„²å­˜ã€‚
    åˆä½µæ‰€æœ‰ `st.data_editor` çš„è®Šæ›´ï¼Œæ›´æ–°ä¸»è³‡æ–™è¡¨ã€‚
    """
    if not st.session_state.edited_dataframes:
        st.info("â„¹ï¸ æ²’æœ‰åµæ¸¬åˆ°ä»»ä½•è¡¨æ ¼ä¿®æ”¹ã€‚")
        return

    main_df = st.session_state.data.copy()
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)
    affected_projects = set()
    changes_detected = False
    
    # éæ­·æ¯å€‹å°ˆæ¡ˆé …ç›®çš„ç·¨è¼¯çµæœ
    for item_name, edited_df in st.session_state.edited_dataframes.items():
        if edited_df.empty: continue
        
        # å°‹æ‰¾è®Šæ›´çš„åˆ—
        for index, new_row in edited_df.iterrows():
            original_id = new_row['ID']
            # åœ¨ä¸»è¡¨ä¸­æ‰¾åˆ°å°æ‡‰çš„åˆ—
            idx_in_main = main_df[main_df['ID'] == original_id].index
            
            if idx_in_main.empty: continue
            main_idx = idx_in_main[0]
            
            # å®šç¾©å¯è¢«ç·¨è¼¯çš„æ¬„ä½ (æ³¨æ„ï¼šä¸åŒ…å« 'é™„ä»¶é€£çµ' ç­‰å‰ç«¯æ¬„ä½)
            updatable_cols = ['é¸å–', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç‹€æ…‹', 'æ¨™è¨˜åˆªé™¤', 'é™„ä»¶URL'] 
            
            # æ¯”å°ä¸¦æ›´æ–°
            for col in updatable_cols:
                # ç¢ºä¿æ¬„ä½å­˜åœ¨ä¸”å€¼æœ‰è®Šå‹•
                if col in new_row and main_df.loc[main_idx, col] != new_row[col]:
                    main_df.loc[main_idx, col] = new_row[col]
                    changes_detected = True
            
            # ç‰¹æ®Šè™•ç†ï¼šè§£ææ—¥æœŸé¡¯ç¤ºå­—ä¸² (å»é™¤å¾Œé¢çš„ emoji)
            try:
                date_val_full = str(new_row['äº¤æœŸé¡¯ç¤º']).strip()
                date_part = date_val_full.split(' ')[0] # å–ç¬¬ä¸€éƒ¨åˆ†
                if main_df.loc[main_idx, 'é è¨ˆäº¤è²¨æ—¥'] != date_part:
                    # é©—è­‰æ—¥æœŸæ ¼å¼
                    datetime.strptime(date_part, DATE_FORMAT)
                    main_df.loc[main_idx, 'é è¨ˆäº¤è²¨æ—¥'] = date_part
                    changes_detected = True
            except (ValueError, IndexError): 
                pass # æ ¼å¼éŒ¯èª¤å‰‡å¿½ç•¥
            
            # è‡ªå‹•è¨ˆç®—ç¸½åƒ¹ (å–®åƒ¹ * æ•¸é‡)
            try:
                new_total = float(new_row['å–®åƒ¹']) * float(new_row['æ•¸é‡'])
                if main_df.loc[main_idx, 'ç¸½åƒ¹'] != new_total:
                    main_df.loc[main_idx, 'ç¸½åƒ¹'] = new_total
                    changes_detected = True
            except (ValueError, TypeError):
                pass
            
            affected_projects.add(main_df.loc[main_idx, 'å°ˆæ¡ˆåç¨±'])

    if changes_detected:
        # æ›´æ–° Metadata çš„æœ€å¾Œä¿®æ”¹æ™‚é–“
        for proj in affected_projects:
            if proj in st.session_state.project_metadata:
                st.session_state.project_metadata[proj]['last_modified'] = current_time_str
        
        # æ›´æ–° Session State
        st.session_state.data = main_df
        save_and_rerun(st.session_state.data, st.session_state.project_metadata, "âœ… æ‰€æœ‰è®Šæ›´å·²å„²å­˜ï¼Google Sheets åŒæ­¥å®Œæˆã€‚")
    else:
        st.info("â„¹ï¸ è³‡æ–™æœªç™¼ç”Ÿå¯¦è³ªè®Šæ›´ã€‚")

def trigger_delete_confirmation():
    """
    è§¸ç™¼åˆªé™¤ç¢ºèªæµç¨‹ã€‚
    å…ˆå°‡ UI ä¸Šçš„å‹¾é¸ç‹€æ…‹åŒæ­¥åˆ°æš«å­˜è³‡æ–™ï¼Œå†è¨ˆç®—è¦åˆªé™¤çš„ç­†æ•¸ã€‚
    """
    # 1. å…ˆå»ºç«‹ä¸€ä»½æš«å­˜çš„ dataï¼ŒåŒ…å«ä½¿ç”¨è€…å‰›å‰›åœ¨ data_editor å‹¾é¸çš„å…§å®¹
    temp_df = st.session_state.data.copy()
    
    # æ”¶é›†æ‰€æœ‰ 'æ¨™è¨˜åˆªé™¤' çš„è®Šæ›´
    deletion_updates = []
    for _, edited_df in st.session_state.edited_dataframes.items():
        if not edited_df.empty:
            # åªå– ID å’Œ æ¨™è¨˜åˆªé™¤ æ¬„ä½
            subset = edited_df[['ID', 'æ¨™è¨˜åˆªé™¤']]
            deletion_updates.append(subset)
            
    if deletion_updates:
        # åˆä½µæ‰€æœ‰æ›´æ–°
        combined_updates = pd.concat(deletion_updates)
        # è¨­å®š index ä»¥ä¾¿ update
        temp_df.set_index('ID', inplace=True)
        combined_updates.set_index('ID', inplace=True)
        # æ›´æ–° temp_df
        temp_df.update(combined_updates)
        temp_df.reset_index(inplace=True)

    # 2. çµ±è¨ˆè¦åˆªé™¤çš„ ID
    # è½‰æ›ç‚º boolean é¿å…å‹åˆ¥å•é¡Œ
    temp_df['æ¨™è¨˜åˆªé™¤'] = temp_df['æ¨™è¨˜åˆªé™¤'].apply(lambda x: True if x == True or str(x).lower() == 'true' else False)
    ids_to_delete = temp_df[temp_df['æ¨™è¨˜åˆªé™¤'] == True]['ID'].tolist()
    
    if not ids_to_delete:
        st.warning("âš ï¸ æ²’æœ‰é …ç›®è¢«æ¨™è¨˜ç‚ºåˆªé™¤ã€‚è«‹å…ˆåœ¨è¡¨æ ¼å³å´å‹¾é¸ 'åˆªé™¤?' æ¬„ä½ã€‚")
        st.session_state.show_delete_confirm = False
        return

    # 3. é€²å…¥ç¢ºèªç‹€æ…‹
    st.session_state.delete_count = len(ids_to_delete)
    st.session_state.ids_pending_delete = ids_to_delete # æš«å­˜è¦åˆªé™¤çš„ ID
    st.session_state.show_delete_confirm = True
    st.rerun()

def handle_batch_delete_quotes():
    """åŸ·è¡Œå¯¦éš›çš„åˆªé™¤æ“ä½œã€‚"""
    ids_to_delete = st.session_state.get('ids_pending_delete', [])
    
    if not ids_to_delete:
        st.error("æ‰¾ä¸åˆ°å¾…åˆªé™¤çš„ IDã€‚")
        st.session_state.show_delete_confirm = False
        st.rerun()
        return
    
    # åŸ·è¡Œéæ¿¾
    current_data = st.session_state.data
    new_data = current_data[~current_data['ID'].isin(ids_to_delete)].reset_index(drop=True)
    
    # æ›´æ–° Session State
    st.session_state.data = new_data
    
    # é‡ç½®ç‹€æ…‹
    st.session_state.show_delete_confirm = False
    st.session_state.delete_count = 0
    st.session_state.ids_pending_delete = []
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²æ°¸ä¹…åˆªé™¤ {len(ids_to_delete)} ç­†è³‡æ–™ã€‚")

def cancel_delete_confirmation():
    """å–æ¶ˆåˆªé™¤æ“ä½œã€‚"""
    st.session_state.show_delete_confirm = False
    st.session_state.ids_pending_delete = []
    st.rerun()

def handle_project_modification():
    """ä¿®æ”¹å°ˆæ¡ˆåç¨±èˆ‡æ™‚ç¨‹ã€‚"""
    target_proj = st.session_state.edit_target_project
    new_name = st.session_state.edit_new_name
    new_date = st.session_state.edit_new_date
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)
    
    if not new_name:
        st.error("âŒ å°ˆæ¡ˆåç¨±ä¸èƒ½ç‚ºç©º")
        return
        
    # æª¢æŸ¥åç¨±è¡çª
    if target_proj != new_name and new_name in st.session_state.project_metadata:
        st.error(f"âŒ æ–°çš„å°ˆæ¡ˆåç¨± '{new_name}' å·²å­˜åœ¨ï¼Œè«‹ä½¿ç”¨ä¸åŒåç¨±ã€‚")
        return

    # æ›´æ–° Metadata
    meta = st.session_state.project_metadata.pop(target_proj)
    meta['due_date'] = new_date
    meta['last_modified'] = current_time_str
    st.session_state.project_metadata[new_name] = meta
    
    # æ›´æ–° Data ä¸­çš„å°ˆæ¡ˆåç¨±
    st.session_state.data.loc[st.session_state.data['å°ˆæ¡ˆåç¨±'] == target_proj, 'å°ˆæ¡ˆåç¨±'] = new_name
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å°ˆæ¡ˆè³‡è¨Šå·²æ›´æ–°ï¼š{new_name}ã€‚")

def handle_delete_project(project_to_delete):
    """åˆªé™¤æ•´å€‹å°ˆæ¡ˆã€‚"""
    if not project_to_delete: return
    
    # ç§»é™¤ Metadata
    if project_to_delete in st.session_state.project_metadata:
        del st.session_state.project_metadata[project_to_delete]
    
    # ç§»é™¤ Data ä¸­ç›¸é—œåˆ—
    original_count = len(st.session_state.data)
    st.session_state.data = st.session_state.data[st.session_state.data['å°ˆæ¡ˆåç¨±'] != project_to_delete].reset_index(drop=True)
    deleted_count = original_count - len(st.session_state.data)
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å°ˆæ¡ˆ {project_to_delete} åŠå…¶ {deleted_count} ç­†å ±åƒ¹å·²åˆªé™¤ã€‚")

def handle_add_new_project():
    """æ–°å¢å°ˆæ¡ˆè¨­å®šã€‚"""
    project_name = st.session_state.new_proj_name
    project_due_date = st.session_state.new_proj_due_date
    buffer_days = st.session_state.new_proj_buffer_days
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)

    if not project_name:
        st.error("âŒ å°ˆæ¡ˆåç¨±ä¸èƒ½ç‚ºç©ºã€‚")
        return
        
    if project_name in st.session_state.project_metadata:
        st.info(f"â„¹ï¸ å°ˆæ¡ˆ '{project_name}' å·²å­˜åœ¨ï¼Œå°‡æ›´æ–°å…¶è¨­å®šã€‚")

    st.session_state.project_metadata[project_name] = {
        'due_date': project_due_date, 
        'buffer_days': buffer_days,
        'last_modified': current_time_str
    }
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²å„²å­˜å°ˆæ¡ˆè¨­å®šï¼š{project_name}ã€‚")

def handle_add_new_quote(latest_arrival_date, uploaded_file):
    """æ–°å¢å–®ç­†å ±åƒ¹ã€‚"""
    project_name = st.session_state.quote_project_select
    item_name_to_use = st.session_state.item_name_to_use_final
    supplier = st.session_state.quote_supplier
    price = st.session_state.quote_price
    qty = st.session_state.quote_qty
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)
    
    # æ±ºå®šäº¤è²¨æ—¥æœŸ
    if st.session_state.quote_date_type == "1. æŒ‡å®šæ—¥æœŸ":
        final_delivery_date = st.session_state.quote_delivery_date
    else:
        final_delivery_date = st.session_state.calculated_delivery_date 

    # é©—è­‰è¼¸å…¥
    if not project_name:
        st.error("âŒ è«‹é¸æ“‡å°ˆæ¡ˆã€‚")
        return
    if not item_name_to_use:
        st.error("âŒ è«‹è¼¸å…¥æˆ–é¸æ“‡æ¡è³¼é …ç›®ã€‚")
        return

    total_price = price * qty
    
    # GCS ä¸Šå‚³æµç¨‹
    attachment_uri = ""
    next_id = st.session_state.next_id
    
    if uploaded_file is not None:
        with st.spinner(f"æ­£åœ¨ä¸Šå‚³é™„ä»¶ {uploaded_file.name}..."):
            attachment_uri = upload_attachment_to_gcs(uploaded_file, next_id)
            if attachment_uri is None: 
                # ä¸Šå‚³å¤±æ•—ï¼Œä¸­æ–·æµç¨‹
                return 

    # æ›´æ–°å°ˆæ¡ˆæœ€å¾Œä¿®æ”¹æ™‚é–“
    if project_name in st.session_state.project_metadata:
        st.session_state.project_metadata[project_name]['last_modified'] = current_time_str

    # å»ºç«‹æ–°è³‡æ–™åˆ—
    new_row = {
        'ID': st.session_state.next_id, 
        'é¸å–': False, 
        'å°ˆæ¡ˆåç¨±': project_name, 
        'å°ˆæ¡ˆé …ç›®': item_name_to_use, 
        'ä¾›æ‡‰å•†': supplier, 
        'å–®åƒ¹': price, 
        'æ•¸é‡': qty, 
        'ç¸½åƒ¹': total_price, 
        'é è¨ˆäº¤è²¨æ—¥': final_delivery_date.strftime(DATE_FORMAT), 
        'ç‹€æ…‹': st.session_state.quote_status, 
        'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥': latest_arrival_date.strftime(DATE_FORMAT), 
        'æ¨™è¨˜åˆªé™¤': False,
        'é™„ä»¶URL': attachment_uri 
    }
    
    st.session_state.next_id += 1
    st.session_state.data = pd.concat([st.session_state.data, pd.DataFrame([new_row])], ignore_index=True)
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²æˆåŠŸæ–°å¢å ±åƒ¹è‡³ {project_name}ï¼")


# --- åˆå§‹åŒ– Session State ---
def initialize_session_state():
    """åˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„ Session State è®Šæ•¸ã€‚"""
    today = datetime.now().date()
    
    # é¦–æ¬¡è¼‰å…¥æ•¸æ“š
    if 'data' not in st.session_state:
        data_df, metadata_dict = load_data_from_sheets()
        st.session_state.data = data_df
        st.session_state.project_metadata = metadata_dict
        
    # è¨ˆç®—ä¸‹ä¸€å€‹ ID
    if not st.session_state.data.empty:
        try:
            current_max = st.session_state.data['ID'].max()
            next_id_val = int(current_max) + 1 if pd.notna(current_max) else 1
        except:
            next_id_val = 1
    else:
        next_id_val = 1
    
    # åˆå§‹åŒ–å…¶é¤˜è®Šæ•¸
    initial_values = {
        'next_id': next_id_val,
        'edited_dataframes': {}, # å„²å­˜æ¯å€‹è¡¨æ ¼çš„ç·¨è¼¯ç‹€æ…‹
        'calculated_delivery_date': today,
        'show_delete_confirm': False,
        'delete_count': 0,
        'ids_pending_delete': []
    }
    
    for key, value in initial_values.items():
        if key not in st.session_state:
            st.session_state[key] = value
            
    # ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
    if 'æ¨™è¨˜åˆªé™¤' not in st.session_state.data.columns: 
        st.session_state.data['æ¨™è¨˜åˆªé™¤'] = False
    if 'é™„ä»¶URL' not in st.session_state.data.columns: 
        st.session_state.data['é™„ä»¶URL'] = ""


# --- ä¸»æ‡‰ç”¨ç¨‹å¼é‚è¼¯ ---
def run_app():
    st.title(f"ğŸ› ï¸ å°ˆæ¡ˆæ¡è³¼ç®¡ç†å·¥å…· {APP_VERSION}") 
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    
    initialize_session_state()
    
    # æ¯æ¬¡é‡è·‘æ™‚é‡æ–°è¨ˆç®—æœ€æ…¢åˆ°è²¨æ—¥ (ç¢ºä¿æ™‚ç¨‹è®Šæ›´æ™‚å³æ™‚åæ˜ )
    st.session_state.data = calculate_latest_arrival_dates(st.session_state.data, st.session_state.project_metadata)
    
    if st.session_state.get('data_load_failed', False):
        st.warning("âš ï¸ æ‡‰ç”¨ç¨‹å¼ç›®å‰ç„¡æ³•å¾ Google Sheets è¼‰å…¥æ•¸æ“šï¼Œè«‹æª¢æŸ¥é€£ç·šæˆ–é…ç½®ã€‚")
        
    today = datetime.now().date() 

    # --- æ—¥æœŸæ ¼å¼åŒ– (ä¾›å‰ç«¯é¡¯ç¤ºç”¨ï¼ŒåŠ ä¸Šç´…ç¶ ç‡ˆ) ---
    def format_date_with_icon(row):
        date_str = str(row['é è¨ˆäº¤è²¨æ—¥'])
        try:
            v_date = pd.to_datetime(row['é è¨ˆäº¤è²¨æ—¥']).date()
            l_date = pd.to_datetime(row['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥']).date()
            # è‹¥é è¨ˆäº¤è²¨æ—¥ > æœ€æ…¢åˆ°è²¨æ—¥ï¼Œé¡¯ç¤ºç´…ç‡ˆ
            return f"{date_str} ğŸ”´" if v_date > l_date else f"{date_str} âœ…"
        except: 
            return date_str

    # å»ºç«‹é¡¯ç¤ºç”¨çš„æ¬„ä½ï¼Œä¸å½±éŸ¿åŸå§‹æ•¸æ“š
    if not st.session_state.data.empty:
        st.session_state.data['äº¤æœŸé¡¯ç¤º'] = st.session_state.data.apply(format_date_with_icon, axis=1)

    df = st.session_state.data
    # ä¾å°ˆæ¡ˆåˆ†çµ„
    if not df.empty:
        project_groups = df.groupby('å°ˆæ¡ˆåç¨±')
    else:
        project_groups = []
    
    # ==========================
    #      å´é‚Šæ¬„ (Sidebar)
    # ==========================
    with st.sidebar:
        st.button("ğŸšª ç™»å‡ºç³»çµ±", on_click=logout, type="secondary", use_container_width=True)
        st.markdown("---")

        # 1. ä¿®æ”¹/åˆªé™¤å°ˆæ¡ˆ
        with st.expander("âœï¸ ä¿®æ”¹/åˆªé™¤å°ˆæ¡ˆè³‡è¨Š", expanded=False):
            all_projects = sorted(list(st.session_state.project_metadata.keys()))
            if all_projects:
                target_proj = st.selectbox("é¸æ“‡ç›®æ¨™å°ˆæ¡ˆ", all_projects, key="edit_target_project")
                operation = st.selectbox("é¸æ“‡æ“ä½œ", ("ä¿®æ”¹å°ˆæ¡ˆè³‡è¨Š", "åˆªé™¤å°ˆæ¡ˆ"), key="project_operation_select")
                st.markdown("---")
                
                current_meta = st.session_state.project_metadata.get(target_proj, {'due_date': today})
                
                if operation == "ä¿®æ”¹å°ˆæ¡ˆè³‡è¨Š":
                    st.text_input("æ–°å°ˆæ¡ˆåç¨±", value=target_proj, key="edit_new_name")
                    st.date_input("æ–°å°ˆæ¡ˆäº¤è²¨æ—¥", value=current_meta['due_date'], key="edit_new_date")
                    if st.button("ç¢ºèªä¿®æ”¹", type="primary", use_container_width=True): 
                        handle_project_modification()
                elif operation == "åˆªé™¤å°ˆæ¡ˆ":
                    st.warning(f"âš ï¸ ç¢ºèªæ°¸ä¹…åˆªé™¤å°ˆæ¡ˆ [{target_proj}]ï¼Ÿ\næ­¤æ“ä½œä¸å¯é€†ï¼Œå°‡åŒæ™‚åˆªé™¤æ‰€æœ‰é—œè¯å ±åƒ¹ã€‚")
                    if st.button("ğŸ”¥ ç¢ºèªæ°¸ä¹…åˆªé™¤", type="secondary", use_container_width=True): 
                        handle_delete_project(target_proj)
            else: 
                st.info("ç›®å‰ç„¡å°ˆæ¡ˆè³‡æ–™ã€‚")
        
        st.markdown("---")
        
        # 2. æ–°å¢å°ˆæ¡ˆ
        with st.expander("â• æ–°å¢/è¨­å®šå°ˆæ¡ˆæ™‚ç¨‹", expanded=False):
            st.text_input("å°ˆæ¡ˆåç¨±", key="new_proj_name", placeholder="ä¾‹å¦‚: è¾¦å…¬å®¤å‡ç´š")
            project_due_date = st.date_input("å°ˆæ¡ˆäº¤è²¨æ—¥", value=today + timedelta(days=30), key="new_proj_due_date")
            buffer_days = st.number_input("æ¡è³¼ç·©è¡å¤©æ•¸", min_value=0, value=7, key="new_proj_buffer_days")
            
            calc_date = project_due_date - timedelta(days=int(buffer_days))
            st.info(f"ğŸ“… è¨ˆç®—ä¹‹æœ€æ…¢åˆ°è²¨æ—¥ï¼š{calc_date.strftime('%Y-%m-%d')}")
            
            if st.button("ğŸ’¾ å„²å­˜å°ˆæ¡ˆè¨­å®š", key="btn_save_proj", use_container_width=True): 
                handle_add_new_project()
        
        st.markdown("---")
        
        # 3. æ–°å¢å ±åƒ¹ (GCSç‰ˆ)
        with st.expander("â• æ–°å¢å ±åƒ¹", expanded=True):
            all_projects_for_quote = sorted(list(st.session_state.project_metadata.keys()))
            latest_arrival_date = today 
            
            if not all_projects_for_quote:
                st.warning("è«‹å…ˆåœ¨ä¸Šæ–¹æ–°å¢å°ˆæ¡ˆã€‚")
                project_name = None
            else:
                project_name = st.selectbox("æ­¸å±¬å°ˆæ¡ˆ", all_projects_for_quote, key="quote_project_select")
                # å–å¾—è©²å°ˆæ¡ˆè¨­å®š
                current_meta = st.session_state.project_metadata.get(project_name, {'due_date': today, 'buffer_days': 7})
                latest_arrival_date = current_meta['due_date'] - timedelta(days=int(current_meta['buffer_days']))
                st.caption(f"æ­¤å°ˆæ¡ˆæœ€æ…¢åˆ°è²¨æœŸé™: {latest_arrival_date.strftime('%Y-%m-%d')}")

            # é …ç›®é¸æ“‡ (æ”¯æ´æ–°å¢)
            unique_items = sorted(st.session_state.data['å°ˆæ¡ˆé …ç›®'].unique().tolist())
            unique_items = [i for i in unique_items if i] # éæ¿¾ç©ºå€¼
            
            selected_item = st.selectbox("æ¡è³¼é …ç›®", ['ğŸ†• æ–°å¢é …ç›®...'] + unique_items, key="quote_item_select")
            
            if selected_item == 'ğŸ†• æ–°å¢é …ç›®...':
                item_name_to_use = st.text_input("è¼¸å…¥æ–°é …ç›®åç¨±", key="quote_item_new_input")
            else:
                item_name_to_use = selected_item
                
            st.session_state.item_name_to_use_final = item_name_to_use
            
            col_sup, col_pr = st.columns(2)
            with col_sup:
                st.text_input("ä¾›æ‡‰å•†", key="quote_supplier")
            with col_pr:
                st.number_input("å–®åƒ¹", min_value=0, key="quote_price")
                
            st.number_input("æ•¸é‡", min_value=1, value=1, key="quote_qty")
            
            st.markdown("---")
            st.markdown("ğŸ“† **é è¨ˆäº¤è²¨æ—¥è¨­å®š**")
            date_input_type = st.radio("è¼¸å…¥æ–¹å¼", ("1. æŒ‡å®šæ—¥æœŸ", "2. è‡ªç„¶æ—¥æ•¸", "3. å·¥ä½œæ—¥æ•¸"), key="quote_date_type", horizontal=True, label_visibility="collapsed")
            
            if date_input_type == "1. æŒ‡å®šæ—¥æœŸ": 
                st.date_input("é¸æ“‡æ—¥æœŸ", today, key="quote_delivery_date") 
            elif date_input_type == "2. è‡ªç„¶æ—¥æ•¸": 
                num_days = st.number_input("å¹¾å¤©å¾Œäº¤è²¨?", 1, value=7, key="quote_num_days_input")
                st.session_state.calculated_delivery_date = today + timedelta(days=int(num_days))
            elif date_input_type == "3. å·¥ä½œæ—¥æ•¸": 
                num_b_days = st.number_input("å¹¾å€‹å·¥ä½œå¤©?", 1, value=5, key="quote_num_b_days_input")
                st.session_state.calculated_delivery_date = add_business_days(today, int(num_b_days))
            
            if date_input_type != "1. æŒ‡å®šæ—¥æœŸ":
                st.info(f"è¨ˆç®—çµæœï¼š{st.session_state.calculated_delivery_date.strftime('%Y-%m-%d')}")

            st.selectbox("åˆå§‹ç‹€æ…‹", STATUS_OPTIONS, key="quote_status")
            
            st.markdown("ğŸ“ **é™„ä»¶ä¸Šå‚³**")
            uploaded_file = st.file_uploader("æ”¯æ´ PDF/åœ–ç‰‡", type=['pdf', 'jpg', 'jpeg', 'png'], key="new_quote_file_uploader")

            if st.button("ğŸ“¥ æ–°å¢è³‡æ–™", key="btn_add_quote", type="primary", use_container_width=True):
                handle_add_new_quote(latest_arrival_date, uploaded_file)


    # ==========================
    #      ä¸»ç•«é¢ (Main)
    # ==========================
    
    # --- å„€è¡¨æ¿ Metrics ---
    total_projects, total_budget, risk_items, pending_quotes = calculate_dashboard_metrics(df, st.session_state.project_metadata)

    st.subheader("ğŸ“Š ç¸½è¦½å„€è¡¨æ¿")
    c1, c2, c3, c4 = st.columns(4)
    c1.markdown(f"<div class='metric-box'><div class='metric-title'>å°ˆæ¡ˆç¸½æ•¸</div><div class='metric-value'>{total_projects}</div></div>", unsafe_allow_html=True)
    c2.markdown(f"<div class='metric-box' style='background:#1E3A2F; border-color:#2E5A48'><div class='metric-title'>ç¸½é ç®— (é ä¼°/å·²é¸)</div><div class='metric-value'>${total_budget:,.0f}</div></div>", unsafe_allow_html=True)
    c3.markdown(f"<div class='metric-box' style='background:#3E2020; border-color:#5A2E2E'><div class='metric-title'>äº¤æœŸé¢¨éšªé …</div><div class='metric-value'>{risk_items}</div></div>", unsafe_allow_html=True)
    c4.markdown(f"<div class='metric-box' style='background:#202E3E; border-color:#2E405A'><div class='metric-title'>å¾…è™•ç†å ±åƒ¹</div><div class='metric-value'>{pending_quotes}</div></div>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # --- æ‰¹æ¬¡æ“ä½œå·¥å…·åˆ— ---
    col_save, col_delete = st.columns([0.8, 0.2])
    is_locked = st.session_state.show_delete_confirm
    
    with col_save:
        if st.button("ğŸ’¾ å„²å­˜æ‰€æœ‰è¡¨æ ¼ä¿®æ”¹ (ä¸¦é‡æ–°è¨ˆç®—ç¸½åƒ¹)", type="primary", disabled=is_locked):
            handle_master_save()
            
    with col_delete:
        if st.button("ğŸ—‘ï¸ åˆªé™¤å·²æ¨™è¨˜é …ç›®", type="secondary", disabled=is_locked, key="btn_trigger_delete"):
            trigger_delete_confirmation()

    # --- åˆªé™¤ç¢ºèªå°è©±æ¡† ---
    if st.session_state.show_delete_confirm:
        st.markdown(
            f"""
            <div style="padding: 1rem; border: 1px solid #ff4b4b; border-radius: 0.5rem; background-color: rgba(255, 75, 75, 0.1); margin-bottom: 1rem;">
                <h4 style="color: #ff4b4b; margin:0;">âš ï¸ å±éšªæ“ä½œç¢ºèª</h4>
                <p style="margin: 0.5rem 0;">æ‚¨å³å°‡æ°¸ä¹…åˆªé™¤ <strong>{st.session_state.delete_count}</strong> ç­†è³‡æ–™ã€‚æ­¤æ“ä½œç„¡æ³•å¾©åŸï¼</p>
            </div>
            """, 
            unsafe_allow_html=True
        )
        col_yes, col_no, _ = st.columns([0.15, 0.15, 0.7])
        with col_yes: 
            if st.button("âœ… ç¢ºèªåˆªé™¤", key="confirm_delete_yes", type="primary"): 
                handle_batch_delete_quotes()
        with col_no: 
            if st.button("âŒ å–æ¶ˆ", key="confirm_delete_no"): 
                cancel_delete_confirmation()

    st.markdown("---")

    # --- å°ˆæ¡ˆåˆ—è¡¨ (æ ¸å¿ƒè¡¨æ ¼å€åŸŸ) ---
    if not project_groups:
        st.info("ğŸ‘‹ æ­¡è¿ä½¿ç”¨ï¼ç›®å‰æ²’æœ‰è³‡æ–™ï¼Œè«‹å¾å·¦å´å´é‚Šæ¬„æ–°å¢å°ˆæ¡ˆèˆ‡å ±åƒ¹ã€‚")
    
    for proj_name, proj_data in project_groups:
        meta = st.session_state.project_metadata.get(proj_name, {})
        proj_budget = calculate_project_budget(df, proj_name)
        last_mod = meta.get('last_modified', 'N/A')
        
        # å°ˆæ¡ˆæ¨™é¡Œ HTML
        header_html = f"""
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <span class='project-header'>ğŸ’¼ {proj_name}</span> &nbsp;
                <span class='meta-info'>(äº¤æœŸ: {meta.get('due_date')})</span>
            </div>
            <div>
                <span class='project-header'>${proj_budget:,.0f}</span>
            </div>
        </div>
        <div style="font-size: 0.8em; color: #666; text-align: right; margin-top: -5px;">æœ€å¾Œä¿®æ”¹: {last_mod}</div>
        """
        
        with st.expander(label=f"å°ˆæ¡ˆï¼š{proj_name}", expanded=False):
            st.markdown(header_html, unsafe_allow_html=True)
            
            # ä¾é …ç›®åˆ†çµ„
            for item_name, item_data in proj_data.groupby('å°ˆæ¡ˆé …ç›®'):
                st.markdown(f"<span class='item-header'>ğŸ“¦ {item_name}</span>", unsafe_allow_html=True)
                
                # --- æº–å‚™é¡¯ç¤ºç”¨çš„ DataFrame ---
                display_df = item_data.copy()
                display_df['é™„ä»¶é€£çµ'] = None
                
                # é å…ˆç”Ÿæˆ Signed URL (é‡å°æ­¤å€å¡Šçš„è³‡æ–™)
                # é€™è£¡ä½¿ç”¨ cached function ä»¥æå‡æ•ˆèƒ½
                for idx, row in display_df.iterrows():
                    uri = row.get('é™„ä»¶URL', '')
                    if uri and isinstance(uri, str) and uri.strip():
                        signed_url = generate_signed_url_cached(uri)
                        if signed_url:
                            display_df.at[idx, 'é™„ä»¶é€£çµ'] = signed_url

                editor_key = f"ed_{proj_name}_{item_name}"
                
                # --- å®šç¾©æ¬„ä½é †åºèˆ‡é…ç½® ---
                # éš±è—åŸå§‹ GS è·¯å¾‘ï¼Œå°‡ 'é™„ä»¶é€£çµ' æ”¾åœ¨é¡¯çœ¼ä½ç½®
                column_order = [
                    'ID', 'é¸å–', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 
                    'äº¤æœŸé¡¯ç¤º', 'ç‹€æ…‹', 'é™„ä»¶é€£çµ', 'æ¨™è¨˜åˆªé™¤', 
                    'é™„ä»¶URL' # æ”¾åˆ°æœ€å¾Œä¸¦éš±è—/å”¯è®€
                ]

                edited_df_value = st.data_editor(
                    display_df[column_order],
                    column_config={
                        "ID": st.column_config.NumberColumn(
                            "ID", disabled=True, width="small"
                        ),
                        "é¸å–": st.column_config.CheckboxColumn(
                            "é¸", width="small", help="å‹¾é¸ä»¥è¨ˆå…¥é ç®—"
                        ),
                        "ä¾›æ‡‰å•†": st.column_config.TextColumn(
                            "ä¾›æ‡‰å•†", width="medium"
                        ),
                        "å–®åƒ¹": st.column_config.NumberColumn(
                            "å–®åƒ¹", format="$%d", min_value=0
                        ),
                        "æ•¸é‡": st.column_config.NumberColumn(
                            "æ•¸", min_value=1, width="small"
                        ),
                        "ç¸½åƒ¹": st.column_config.NumberColumn(
                            "ç¸½åƒ¹", format="$%d", disabled=True
                        ),
                        "äº¤æœŸé¡¯ç¤º": st.column_config.TextColumn(
                            "é è¨ˆäº¤è²¨æ—¥", disabled=False, width="medium", help="æ ¼å¼: YYYY-MM-DD"
                        ),
                        "ç‹€æ…‹": st.column_config.SelectboxColumn(
                            "ç‹€æ…‹", options=STATUS_OPTIONS, width="small"
                        ),
                        # æ ¸å¿ƒä¿®å¾©ï¼šä½¿ç”¨ LinkColumn é¡¯ç¤ºç°½ç½²å¾Œçš„ URL
                        "é™„ä»¶é€£çµ": st.column_config.LinkColumn(
                            "é™„ä»¶æª”æ¡ˆ", 
                            display_text="ğŸ“„ é–‹å•Ÿé™„ä»¶", 
                            help="é»æ“Šåœ¨æ–°åˆ†é é è¦½é™„ä»¶ (æœ‰æ•ˆæœŸ1å°æ™‚)",
                            width="medium"
                        ),
                        "æ¨™è¨˜åˆªé™¤": st.column_config.CheckboxColumn(
                            "åˆªé™¤?", width="small", help="å‹¾é¸å¾Œé»æ“Šä¸Šæ–¹ç´…è‰²æŒ‰éˆ•åŸ·è¡Œåˆªé™¤"
                        ),
                        # éš±è—æˆ–ç¸®å°åŸå§‹è·¯å¾‘
                        "é™„ä»¶URL": st.column_config.TextColumn(
                            "ç³»çµ±è·¯å¾‘", 
                            disabled=True, 
                            width="small",
                            help="åŸå§‹ GCS è·¯å¾‘ (gs://)"
                        ),
                    },
                    hide_index=True,
                    key=editor_key,
                    disabled=is_locked
                )
                
                # å„²å­˜ç·¨è¼¯ç‹€æ…‹åˆ° Session State
                st.session_state.edited_dataframes[item_name] = edited_df_value 
                
                st.markdown("---")

    # --- è³‡æ–™åŒ¯å‡ºå€å¡Š ---
    st.markdown("<br>", unsafe_allow_html=True)
    st.subheader("ğŸ’¾ è³‡æ–™å‚™ä»½èˆ‡åŒ¯å‡º")
    
    col_dl, _ = st.columns([0.2, 0.8])
    with col_dl:
        file_name = f'procurement_report_{datetime.now().strftime("%Y%m%d")}.xlsx'
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel å ±è¡¨", 
            data=convert_df_to_excel(df), 
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )


def main():
    # é€²å…¥é»ï¼šå…ˆé©—è­‰ç™»å…¥
    login_form()
    
    # åªæœ‰é©—è­‰é€šéæ‰åŸ·è¡Œä¸»ç¨‹å¼
    if st.session_state.authenticated:
        run_app() 
        
if __name__ == "__main__":
    main()
