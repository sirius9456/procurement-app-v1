import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO
import os 
import json
import gspread
import logging
import time

# ==============================================================================
# ä¾è³´åº«å°å…¥èˆ‡ç’°å¢ƒåˆå§‹åŒ–
# ==============================================================================

# å¼•å…¥ Google Cloud Storage (GCS) åº«ï¼Œç”¨æ–¼é™„ä»¶ä¸Šå‚³èˆ‡ç°½ç«  URL ç”Ÿæˆ
from google.cloud import storage

# ç¢ºä¿ openpyxl åº«å·²å®‰è£ (ç”¨æ–¼ Excel åŒ¯å‡º)

# --- æ‡‰ç”¨ç¨‹å¼è¨­å®šèˆ‡å¸¸æ•¸å®šç¾© ---
# ä¾ç…§æ‚¨çš„è¦æ±‚ï¼Œç‰ˆæœ¬è™Ÿé–å®šåœ¨ v2.2
APP_VERSION = "v2.2" 
STATUS_OPTIONS = ["å¾…æ¡è³¼", "å·²ä¸‹å–®", "å·²æ”¶è²¨", "å–æ¶ˆ"] # å ±åƒ¹ç‹€æ…‹é¸é …
DATE_FORMAT = "%Y-%m-%d"                            # æ—¥æœŸæ¨™æº–æ ¼å¼
DATETIME_FORMAT = "%Y-%m-%d %H:%M:%S"               # æ™‚é–“æˆ³æ¨™æº–æ ¼å¼

# --- Google Cloud Storage (GCS) é…ç½® ---
# âš ï¸ æ³¨æ„ï¼šè«‹ç¢ºä¿æ‚¨çš„ GCE æœå‹™å¸³æˆ¶æœ‰ Storage Object Admin/Creator æ¬Šé™
GCS_BUCKET_NAME = "procurement-attachments-bucket"
GCS_ATTACHMENT_FOLDER = "attachments"

# --- æ—¥èªŒé…ç½®ï¼šç”¨æ–¼ Streamlit å¾Œç«¯ç´€éŒ„ï¼Œæ–¹ä¾¿é™¤éŒ¯ ---
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- æ•¸æ“šæºé…ç½®ï¼šå„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å– Google Sheets è³‡è¨Š ---
if "GCE_SHEET_URL" in os.environ:
    SHEET_URL = os.environ["GCE_SHEET_URL"]
    try:
        # GSheets æ†‘è­‰è·¯å¾‘ï¼Œç”¨æ–¼ Gspread é€£ç·šèˆ‡ GCS Signed URL ç°½ç½²
        GSHEETS_CREDENTIALS = os.environ["GSHEETS_CREDENTIALS_PATH"] 
    except KeyError:
        logger.error("GSHEETS_CREDENTIALS_PATH is missing in environment.")
        st.error("âŒ åš´é‡éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GSHEETS_CREDENTIALS_PATH ç’°å¢ƒè®Šæ•¸ã€‚")
        GSHEETS_CREDENTIALS = None 
else:
    # é GCE ç’°å¢ƒä¸‹çš„å‚™ç”¨é…ç½®
    try:
        SHEET_URL = st.secrets["app_config"]["sheet_url"]
        GSHEETS_CREDENTIALS = None 
    except KeyError:
        SHEET_URL = None
        GSHEETS_CREDENTIALS = None
        
DATA_SHEET_NAME = "æ¡è³¼ç¸½è¡¨"     # å­˜æ”¾å ±åƒ¹æ•¸æ“šçš„å·¥ä½œè¡¨åç¨±
METADATA_SHEET_NAME = "å°ˆæ¡ˆè¨­å®š" # å­˜æ”¾å°ˆæ¡ˆè¨­å®š (äº¤æœŸ, ç·©è¡å¤©æ•¸) çš„å·¥ä½œè¡¨åç¨±


# --- Streamlit é é¢è¨­å®š ---
st.set_page_config(
    page_title=f"å°ˆæ¡ˆæ¡è³¼å°å¹«æ‰‹ {APP_VERSION}", 
    page_icon="ğŸ› ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS æ¨£å¼å„ªåŒ–ï¼šæå‡å¯è®€æ€§èˆ‡è¦–è¦ºæ•ˆæœ ---
CUSTOM_CSS = """
<style>
    /* å®¹å™¨é–“è·èª¿æ•´ */
    .block-container { padding-top: 1rem; padding-bottom: 2rem; }
    
    /* å°ˆæ¡ˆæ¨™é¡Œæ¨£å¼å„ªåŒ– (V2.1.6 æ¸…æ™°é¢¨æ ¼) */
    .project-card-header {
        background-color: #262730;
        padding: 10px 15px;
        border-radius: 5px;
        border-left: 5px solid #FF4B4B; /* å¢åŠ é‚Šæ¢å¼·èª¿ */
        margin-bottom: 10px;
    }
    .proj-title { font-size: 22px; font-weight: bold; color: #FFFFFF; }
    .proj-meta { font-size: 16px; color: #E0E0E0; margin-left: 10px; }
    .proj-budget { font-size: 18px; font-weight: bold; color: #4CAF50; float: right; }
    
    /* é …ç›®åˆ†éš”ç·š */
    .item-header { 
        font-size: 16px; 
        font-weight: 600; 
        color: #888; 
        margin-top: 15px; 
        border-bottom: 1px solid #444; 
        padding-bottom: 5px;
        margin-bottom: 10px;
    }
    
    /* ç‹€æ…‹ç‡ˆè™Ÿæ¨£å¼ (CSS æ¨£å¼åœ¨æ­¤ç‰ˆæœ¬ç„¡æ•ˆï¼Œä½†ä¿ç•™çµæ§‹) */
    .status-ok { color: #4CAF50; font-weight: bold; }
    .status-risk { color: #FF4B4B; font-weight: bold; }
</style>
"""


# ==============================================================================
# è¼”åŠ©å‡½å¼å€
# ==============================================================================

# --- èº«ä»½é©—è­‰èˆ‡ç™»å‡º ---
def logout():
    """æ¸…é™¤ Session State ä¸¦é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼ä»¥ç™»å‡ºã€‚"""
    st.session_state["authenticated"] = False
    for key in ['data', 'project_metadata', 'edited_dataframes']:
        if key in st.session_state: del st.session_state[key]
    st.rerun()

def login_form():
    """é¡¯ç¤ºç™»å…¥è¡¨å–®ä¸¦é€²è¡Œå¯†ç¢¼é©—è­‰ã€‚"""
    DEFAULT_USERNAME = os.environ.get("AUTH_USERNAME", "dev_user")
    DEFAULT_PASSWORD = os.environ.get("AUTH_PASSWORD", "dev_pwd")
    credentials = {"username": DEFAULT_USERNAME, "password": DEFAULT_PASSWORD}

    if "authenticated" not in st.session_state:
        st.session_state["authenticated"] = False
        
    if st.session_state["authenticated"]: return

    st.markdown("<br><br>", unsafe_allow_html=True)
    _, col_center, _ = st.columns([1, 2, 1])
    with col_center:
        with st.container(border=True):
            st.title("ğŸ” ç³»çµ±ç™»å…¥")
            username = st.text_input("ç”¨æˆ¶å", value=credentials["username"], disabled=True)
            password = st.text_input("å¯†ç¢¼", type="password")
            if st.button("ç™»å…¥", type="primary", use_container_width=True):
                if username.strip() == credentials["username"].strip() and password == credentials["password"]:
                    st.session_state["authenticated"] = True
                    st.rerun()
                else:
                    st.error("å¯†ç¢¼éŒ¯èª¤")
    st.stop() 


# --- GCS æœå‹™ç›¸é—œå‡½å¼ ---
def get_storage_client():
    """
    ç²å– GCS å®¢æˆ¶ç«¯ã€‚å„ªå…ˆä½¿ç”¨ Service Account JSON æª”æ¡ˆé€²è¡Œé©—è­‰ã€‚
    """
    if GSHEETS_CREDENTIALS and os.path.exists(GSHEETS_CREDENTIALS):
        try:
            return storage.Client.from_service_account_json(GSHEETS_CREDENTIALS)
        except Exception as e:
            logger.error(f"GCS Client initialization failed with JSON: {e}")
            # é™ç´šï¼šä½¿ç”¨ç’°å¢ƒé è¨­æ†‘è­‰ (é©ç”¨æ–¼ GCE æœå‹™å¸³æˆ¶)
            return storage.Client() 
    return storage.Client()

def upload_attachment_to_gcs(file_obj, next_id):
    """
    å°‡æª”æ¡ˆä¸Šå‚³åˆ° GCS ç§æœ‰å„²å­˜æ¡¶ã€‚
    """
    if not file_obj: return None
    try:
        client = get_storage_client()
        bucket = client.bucket(GCS_BUCKET_NAME)
        ext = os.path.splitext(file_obj.name)[1]
        ts = datetime.now().strftime("%Y%m%d%H%M%S")
        blob_name = f"{GCS_ATTACHMENT_FOLDER}/{next_id}_{ts}{ext}"
        blob = bucket.blob(blob_name)
        file_obj.seek(0)
        
        # è¨­å®šæª”æ¡ˆ Content Type
        content_type = file_obj.type if file_obj.type else 'application/octet-stream'
        blob.upload_from_file(file_obj, content_type=content_type)
        
        logger.info(f"Attachment uploaded: {blob_name}")
        return f"gs://{GCS_BUCKET_NAME}/{blob_name}"
    except Exception as e:
        logger.exception("GCS upload failed.")
        st.error(f"âŒ é™„ä»¶ä¸Šå‚³å¤±æ•—ã€‚è«‹æª¢æŸ¥ GCS æ¬Šé™é…ç½®æˆ– Bucket åç¨±ã€‚éŒ¯èª¤: {e}")
        return None

@st.cache_data(ttl=3600, show_spinner=False)
def generate_signed_url_cached(gcs_uri):
    """
    ç‚º GCS ç§æœ‰ç‰©ä»¶ç”Ÿæˆå¸¶æœ‰ç°½ç« çš„è‡¨æ™‚ URL (Signed URL)ã€‚
    ç·©å­˜çµæœä»¥æ¸›å°‘ API å‘¼å«ã€‚
    """
    if not gcs_uri or not gcs_uri.startswith("gs://"): return None
    try:
        # è§£æ URI ç²å– Bucket å’Œ Blob
        path_part = gcs_uri[5:]
        parts = path_part.split('/', 1)
        if len(parts) != 2: return None
            
        client = get_storage_client()
        bucket = client.bucket(parts[0])
        blob = bucket.blob(parts[1])
        
        # ç”Ÿæˆ V4 ç°½ç«  (æœ‰æ•ˆæœŸ 1 å°æ™‚)
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(hours=1),
            method="GET"
        )
        return url
        
    except Exception as e:
        logger.error(f"Failed to generate Signed URL for {gcs_uri}: {e}")
        return None

# --- æ•¸æ“šå·¥å…· ---
def add_business_days(start_date, num_days):
    """è¨ˆç®—å·¥ä½œæ—¥ (è·³éé€±æœ«)ã€‚"""
    current_date = start_date
    days_added = 0
    while days_added < num_days:
        current_date += timedelta(days=1)
        if current_date.weekday() < 5: # 0-4 æ˜¯é€±ä¸€åˆ°é€±äº”
            days_added += 1
    return current_date

@st.cache_data
def convert_df_to_excel(df):
    """è½‰æ› DataFrame ç‚º Excel æ ¼å¼ä¾›ä¸‹è¼‰ã€‚"""
    # ç§»é™¤å…§éƒ¨è¼”åŠ©æ¬„ä½
    df_export = df.drop(columns=['æ¨™è¨˜åˆªé™¤', 'äº¤æœŸç‹€æ…‹', 'é™„ä»¶é€£çµ'], errors='ignore').fillna("")
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_export.to_excel(writer, index=False, sheet_name='æ¡è³¼å ±åƒ¹ç¸½è¡¨')
    return output.getvalue()


# --- Gspread æ•¸æ“šè™•ç† (å±•é–‹å¯«æ³•) ---
@st.cache_data(ttl=600, show_spinner="æ­£åœ¨åŒæ­¥ Google Sheets æ•¸æ“š...")
def load_data_from_sheets():
    """å¾ Google Sheets è¼‰å…¥æ‰€æœ‰æ¡è³¼æ•¸æ“šèˆ‡å°ˆæ¡ˆè¨­å®šã€‚"""
    if not SHEET_URL:
        st.warning("âš ï¸ Google Sheets URL å°šæœªé…ç½®ã€‚")
        return pd.DataFrame(), {}
        
    try:
        # é€£ç·šèªè­‰
        gc = gspread.service_account(filename=GSHEETS_CREDENTIALS) if GSHEETS_CREDENTIALS else gspread.service_account()
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 1. è®€å–æ¡è³¼ç¸½è¡¨ (Data) ---
        data_ws = sh.worksheet(DATA_SHEET_NAME)
        data_records = data_ws.get_all_records()
        data_df = pd.DataFrame(data_records)

        # ç¢ºä¿æ ¸å¿ƒæ¬„ä½å­˜åœ¨ï¼Œä¸¦è¨­å®šé è¨­å€¼
        required_cols = ['ID', 'é¸å–', 'å°ˆæ¡ˆåç¨±', 'å°ˆæ¡ˆé …ç›®', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 'é è¨ˆäº¤è²¨æ—¥', 'ç‹€æ…‹', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥', 'æœ€å¾Œä¿®æ”¹æ™‚é–“', 'é™„ä»¶URL', 'æ¨™è¨˜åˆªé™¤']
        for col in required_cols:
            if col not in data_df.columns: 
                data_df[col] = "" # è£œé½Šæ–°æ¬„ä½
        
        # è³‡æ–™é¡å‹åš´æ ¼è½‰æ›
        data_df['ID'] = pd.to_numeric(data_df['ID'], errors='coerce').astype('Int64')
        data_df['å–®åƒ¹'] = pd.to_numeric(data_df['å–®åƒ¹'], errors='coerce').fillna(0).astype('float')
        data_df['æ•¸é‡'] = pd.to_numeric(data_df['æ•¸é‡'], errors='coerce').fillna(1).astype('Int64')
        data_df['ç¸½åƒ¹'] = pd.to_numeric(data_df['ç¸½åƒ¹'], errors='coerce').fillna(0).astype('float')
        
        # å¸ƒæ—å€¼è½‰æ› (ç¢ºä¿ True/False æ ¼å¼æ­£ç¢º)
        data_df['é¸å–'] = data_df['é¸å–'].astype(str).str.upper() == 'TRUE'
        data_df['æ¨™è¨˜åˆªé™¤'] = data_df['æ¨™è¨˜åˆªé™¤'].astype(str).str.upper() == 'TRUE'
        
        logger.info(f"Loaded {len(data_df)} records.")

        # --- 2. è®€å–å°ˆæ¡ˆè¨­å®š (Metadata) ---
        meta_records = sh.worksheet(METADATA_SHEET_NAME).get_all_records()
        project_metadata = {}
        for row in meta_records:
            name = row.get('å°ˆæ¡ˆåç¨±')
            if name:
                project_metadata[name] = {
                    'due_date': pd.to_datetime(str(row.get('å°ˆæ¡ˆäº¤è²¨æ—¥'))).date(),
                    'buffer_days': int(row.get('ç·©è¡å¤©æ•¸', 7)),
                    'last_modified': str(row.get('æœ€å¾Œä¿®æ”¹', ''))
                }
        
        st.toast("âœ… æ•¸æ“šå·²å¾ Google Sheets æ›´æ–°", icon="â˜ï¸")
        return data_df, project_metadata
    except Exception as e:
        logger.exception("Google Sheets æ•¸æ“šè¼‰å…¥å¤±æ•—") 
        st.error(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼éŒ¯èª¤: {e}")
        st.session_state.data_load_failed = True
        return pd.DataFrame(), {}

def write_data_to_sheets(df, meta):
    """å°‡ä¿®æ”¹å¾Œçš„æ•¸æ“šèˆ‡å°ˆæ¡ˆè¨­å®šå¯«å› Google Sheetsã€‚"""
    if st.session_state.get('data_load_failed', False): return False
    try:
        gc = gspread.service_account(filename=GSHEETS_CREDENTIALS)
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 1. å¯«å…¥æ¡è³¼ç¸½è¡¨ ---
        # æ’é™¤å‰ç«¯è¼”åŠ©æ¬„ä½
        export_df = df.drop(columns=['æ¨™è¨˜åˆªé™¤', 'äº¤æœŸç‹€æ…‹', 'é™„ä»¶é€£çµ'], errors='ignore').fillna("")
        
        # ç¢ºä¿æ—¥æœŸæ¬„ä½ç‚ºå­—ä¸²æ ¼å¼
        for col in export_df.columns:
            if pd.api.types.is_datetime64_any_dtype(export_df[col]):
                export_df[col] = export_df[col].dt.strftime(DATE_FORMAT)

        data_ws = sh.worksheet(DATA_SHEET_NAME)
        data_ws.clear()
        data_ws.update([export_df.columns.tolist()] + export_df.values.tolist())
        
        # --- 2. å¯«å…¥å°ˆæ¡ˆè¨­å®š ---
        meta_list = [{'å°ˆæ¡ˆåç¨±': k, 'å°ˆæ¡ˆäº¤è²¨æ—¥': v['due_date'].strftime(DATE_FORMAT), 'ç·©è¡å¤©æ•¸': v['buffer_days'], 'æœ€å¾Œä¿®æ”¹': v['last_modified']} for k,v in meta.items()]
        meta_df = pd.DataFrame(meta_list)
        
        metadata_ws = sh.worksheet(METADATA_SHEET_NAME)
        metadata_ws.clear()
        if not meta_df.empty:
            metadata_ws.update([meta_df.columns.tolist()] + meta_df.values.tolist())
            
        st.cache_data.clear()
        logger.info("Data successfully written to Google Sheets.")
        return True
    except Exception as e:
        logger.exception("Google Sheets write operation failed.")
        st.error(f"âŒ æ•¸æ“šå¯«å›å¤±æ•—ï¼è«‹æª¢æŸ¥æ¬Šé™ã€‚éŒ¯èª¤: {e}")
        return False


# --- æ•¸æ“šè¨ˆç®—èˆ‡æŒ‡æ¨™ ---
def calculate_latest_arrival(df, meta):
    """è¨ˆç®—æ¯å€‹æ¡è³¼é …ç›®çš„æœ€æ…¢åˆ°è²¨æ—¥ (å°ˆæ¡ˆäº¤æœŸ - ç·©è¡å¤©æ•¸)ã€‚"""
    if df.empty or not meta: return df
    meta_df = pd.DataFrame.from_dict(meta, orient='index').reset_index().rename(columns={'index': 'å°ˆæ¡ˆåç¨±'})
    meta_df['due_date'] = pd.to_datetime(meta_df['due_date']).dt.date
    df = pd.merge(df, meta_df[['å°ˆæ¡ˆåç¨±', 'due_date', 'buffer_days']], on='å°ˆæ¡ˆåç¨±', how='left')
    df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'] = (pd.to_datetime(df['due_date']) - pd.to_timedelta(df['buffer_days'].astype(int), unit='D')).dt.strftime(DATE_FORMAT)
    # ç§»é™¤è¼”åŠ©æ¬„ä½
    return df.drop(columns=['due_date', 'buffer_days'], errors='ignore')

def calculate_project_budget(df, project_name):
    """è¨ˆç®—å–®ä¸€å°ˆæ¡ˆçš„ç¸½é ç®— (å·²é¸/é ä¼°æœ€å°å€¼)ã€‚"""
    proj_df = df[df['å°ˆæ¡ˆåç¨±'] == project_name]
    budget = 0
    for _, item in proj_df.groupby('å°ˆæ¡ˆé …ç›®'):
        sel = item[item['é¸å–'] == True]
        budget += sel['ç¸½åƒ¹'].sum() if not sel.empty else item['ç¸½åƒ¹'].min()
    return budget

def calculate_metrics(df, meta):
    """è¨ˆç®—å„€è¡¨æ¿çš„ç¸½é«”æŒ‡æ¨™ã€‚"""
    if df.empty: return 0, 0, 0, 0
    total_projects = len(meta)
    
    # è¨ˆç®—ç¸½é ç®—
    budget = 0
    for _, proj in df.groupby('å°ˆæ¡ˆåç¨±'):
        for _, item in proj.groupby('å°ˆæ¡ˆé …ç›®'):
            sel = item[item['é¸å–'] == True]
            budget += sel['ç¸½åƒ¹'].sum() if not sel.empty else item['ç¸½åƒ¹'].min()
            
    # è¨ˆç®—é¢¨éšªé … (é è¨ˆäº¤è²¨æ—¥ > æœ€æ…¢åˆ°è²¨æ—¥)
    risk = (pd.to_datetime(df['é è¨ˆäº¤è²¨æ—¥'], errors='coerce') > pd.to_datetime(df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'], errors='coerce')).sum()
    
    # è¨ˆç®—å¾…è™•ç† (é 'å·²æ”¶è²¨' æˆ– 'å–æ¶ˆ')
    pending = df[~df['ç‹€æ…‹'].isin(['å·²æ”¶è²¨', 'å–æ¶ˆ'])].shape[0]
    return total_projects, budget, risk, pending


# ==============================================================================
# UI äº‹ä»¶è™•ç†èˆ‡æ•¸æ“šæµæ§åˆ¶
# ==============================================================================

def save_and_rerun(df, meta, msg=""):
    """å„²å­˜è³‡æ–™åˆ° Sheets ä¸¦é‡æ–°æ•´ç† UIã€‚"""
    if write_data_to_sheets(df, meta):
        st.session_state.edited_dataframes = {}
        if msg: 
            st.toast(msg, icon="âœ…")
            time.sleep(1) # çŸ­æš«å»¶é²è®“ä½¿ç”¨è€…çœ‹åˆ° toast
        st.rerun()

def handle_master_save():
    """è™•ç†æ‰€æœ‰è¡¨æ ¼ç·¨è¼¯ï¼Œæ›´æ–°ç¸½åƒ¹ã€æ™‚é–“æˆ³è¨˜ä¸¦å¯«å› Sheetsã€‚"""
    if not st.session_state.edited_dataframes:
        st.info("ç„¡è®Šæ›´")
        return

    main_df = st.session_state.data.copy()
    now_str = datetime.now().strftime(DATETIME_FORMAT)
    changes = False
    
    # éæ­·æ‰€æœ‰è¢«ç·¨è¼¯éçš„ data_editor
    for _, edited_df in st.session_state.edited_dataframes.items():
        if edited_df.empty: continue
        
        for _, new_row in edited_df.iterrows():
            idx = main_df[main_df['ID'] == new_row['ID']].index
            if idx.empty: continue
            idx = idx[0] # ç²å–ä¸»è¡¨ä¸­çš„ç´¢å¼•
            
            row_changed = False
            # æª¢æŸ¥å¯ç·¨è¼¯çš„æ ¸å¿ƒæ¬„ä½
            check_cols = ['é¸å–', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç‹€æ…‹', 'æ¨™è¨˜åˆªé™¤', 'é è¨ˆäº¤è²¨æ—¥']
            
            for col in check_cols:
                val_main = main_df.loc[idx, col]
                val_new = new_row.get(col)
                
                if col == 'é è¨ˆäº¤è²¨æ—¥':
                    # è™•ç† DateColumn è¿”å›çš„ datetime.date/datetime.datetime ç‰©ä»¶
                    if isinstance(val_new, datetime) or isinstance(val_new, type(datetime.now().date())):
                         val_new = val_new.strftime(DATE_FORMAT)
                    
                    if str(val_main) != str(val_new):
                        main_df.loc[idx, col] = val_new
                        row_changed = True
                
                # å…¶ä»–æ¬„ä½æ¯”å°
                elif str(val_main) != str(val_new):
                    main_df.loc[idx, col] = val_new
                    row_changed = True
            
            # é‡æ–°è¨ˆç®—ç¸½åƒ¹
            new_total = float(new_row['å–®åƒ¹']) * float(new_row['æ•¸é‡'])
            if main_df.loc[idx, 'ç¸½åƒ¹'] != new_total:
                main_df.loc[idx, 'ç¸½åƒ¹'] = new_total
                row_changed = True
            
            # è‹¥æœ‰ä»»ä½•è®Šæ›´ï¼Œæ›´æ–°è©²å ±åƒ¹çš„æ™‚é–“æˆ³è¨˜
            if row_changed:
                main_df.loc[idx, 'æœ€å¾Œä¿®æ”¹æ™‚é–“'] = now_str
                changes = True
                
                # åŒæ­¥æ›´æ–°å°ˆæ¡ˆ metadata æ™‚é–“
                proj = main_df.loc[idx, 'å°ˆæ¡ˆåç¨±']
                if proj in st.session_state.project_metadata:
                    st.session_state.project_metadata[proj]['last_modified'] = now_str

    if changes:
        st.session_state.data = main_df
        save_and_rerun(st.session_state.data, st.session_state.project_metadata, "âœ… å„²å­˜æˆåŠŸï¼å ±åƒ¹æ™‚é–“æˆ³è¨˜å·²æ›´æ–°ã€‚")
    else:
        st.info("â„¹ï¸ æœªåµæ¸¬åˆ°å¯¦è³ªè®Šæ›´ã€‚")

def handle_add_new_quote(latest_arrival, file):
    """è™•ç†æ–°å¢å ±åƒ¹é‚è¼¯ï¼ŒåŒ…å« GCS ä¸Šå‚³ã€‚"""
    proj = st.session_state.quote_project_select
    item = st.session_state.item_name_to_use_final
    if not proj or not item:
        st.error("âŒ è«‹å¡«å¯«å°ˆæ¡ˆåç¨±å’Œæ¡è³¼é …ç›®ã€‚")
        return

    uri = ""
    # è™•ç† GCS é™„ä»¶ä¸Šå‚³
    if file:
        with st.spinner(f"æ­£åœ¨ä¸Šå‚³é™„ä»¶ {file.name}..."):
            uri = upload_attachment_to_gcs(file, st.session_state.next_id) or ""

    now_str = datetime.now().strftime(DATETIME_FORMAT)
    
    # æ±ºå®šé è¨ˆäº¤è²¨æ—¥
    if st.session_state.quote_date_type == "1. æŒ‡å®šæ—¥æœŸ":
        del_date = st.session_state.quote_delivery_date
    else:
        # è™•ç† "è‡ªç„¶æ—¥æ•¸" æˆ– "å·¥ä½œæ—¥æ•¸" çš„è¨ˆç®—çµæœ
        del_date = st.session_state.calculated_delivery_date

    # å»ºç«‹æ–°è³‡æ–™åˆ—
    new_row = {
        'ID': st.session_state.next_id, 'é¸å–': False, 'å°ˆæ¡ˆåç¨±': proj, 'å°ˆæ¡ˆé …ç›®': item,
        'ä¾›æ‡‰å•†': st.session_state.quote_supplier, 'å–®åƒ¹': st.session_state.quote_price,
        'æ•¸é‡': st.session_state.quote_qty, 'ç¸½åƒ¹': st.session_state.quote_price * st.session_state.quote_qty,
        'é è¨ˆäº¤è²¨æ—¥': del_date.strftime(DATE_FORMAT), 'ç‹€æ…‹': st.session_state.quote_status,
        'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥': latest_arrival.strftime(DATE_FORMAT), 
        'æœ€å¾Œä¿®æ”¹æ™‚é–“': now_str, 
        'æ¨™è¨˜åˆªé™¤': False, 'é™„ä»¶URL': uri
    }
    
    st.session_state.next_id += 1
    # ä½¿ç”¨ concat æ–¹å¼æ–°å¢æ•¸æ“š
    st.session_state.data = pd.concat([st.session_state.data, pd.DataFrame([new_row])], ignore_index=True)
    st.session_state.project_metadata[proj]['last_modified'] = now_str
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²æˆåŠŸæ–°å¢å ±åƒ¹è‡³ {proj}ï¼")

def handle_project_modification():
    """è™•ç†å°ˆæ¡ˆåç¨±æˆ–äº¤è²¨æ—¥çš„ä¿®æ”¹ã€‚"""
    target_proj = st.session_state.edit_target_project
    new_name = st.session_state.edit_new_name
    new_date = st.session_state.edit_new_date
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)
    
    if not new_name:
        st.error("âŒ å°ˆæ¡ˆåç¨±ä¸èƒ½ç‚ºç©º")
        return
    if target_proj != new_name and new_name in st.session_state.project_metadata:
        st.error(f"âŒ æ–°çš„å°ˆæ¡ˆåç¨± '{new_name}' å·²å­˜åœ¨ã€‚")
        return

    # 1. æ›´æ–° Metadata
    meta = st.session_state.project_metadata.pop(target_proj)
    meta['due_date'] = new_date
    meta['last_modified'] = current_time_str
    st.session_state.project_metadata[new_name] = meta
    
    # 2. æ›´æ–° Dataframe ä¸­æ‰€æœ‰ç›¸é—œåˆ—çš„å°ˆæ¡ˆåç¨±
    st.session_state.data.loc[st.session_state.data['å°ˆæ¡ˆåç¨±'] == target_proj, 'å°ˆæ¡ˆåç¨±'] = new_name
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å°ˆæ¡ˆè³‡è¨Šå·²æ›´æ–°ï¼š{new_name}ã€‚")

def handle_delete_project(project_to_delete):
    """æ°¸ä¹…åˆªé™¤æ•´å€‹å°ˆæ¡ˆåŠå…¶æ‰€æœ‰é—œè¯å ±åƒ¹ã€‚"""
    if not project_to_delete: return
    
    # 1. ç§»é™¤å°ˆæ¡ˆè¨­å®š
    if project_to_delete in st.session_state.project_metadata:
        del st.session_state.project_metadata[project_to_delete]
    
    # 2. å¾æ•¸æ“šä¸­éæ¿¾æ‰è©²å°ˆæ¡ˆçš„æ‰€æœ‰å ±åƒ¹
    original_count = len(st.session_state.data)
    st.session_state.data = st.session_state.data[st.session_state.data['å°ˆæ¡ˆåç¨±'] != project_to_delete].reset_index(drop=True)
    deleted_count = original_count - len(st.session_state.data)
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å°ˆæ¡ˆ {project_to_delete} åŠå…¶ {deleted_count} ç­†å ±åƒ¹å·²åˆªé™¤ã€‚")

def handle_add_new_project():
    """è™•ç†æ–°å¢å°ˆæ¡ˆè¨­å®šã€‚"""
    project_name = st.session_state.new_proj_name
    project_due_date = st.session_state.new_proj_due_date
    buffer_days = st.session_state.new_proj_buffer_days
    current_time_str = datetime.now().strftime(DATETIME_FORMAT)

    if not project_name:
        st.error("âŒ å°ˆæ¡ˆåç¨±ä¸èƒ½ç‚ºç©ºã€‚")
        return
        
    st.session_state.project_metadata[project_name] = {
        'due_date': project_due_date, 
        'buffer_days': buffer_days,
        'last_modified': current_time_str
    }
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²å„²å­˜å°ˆæ¡ˆè¨­å®šï¼š{project_name}ã€‚")

def trigger_delete_confirmation():
    """è§¸ç™¼ç¢ºèªåˆªé™¤æ¨™è¨˜é …ç›®çš„æµç¨‹ã€‚"""
    temp_df = st.session_state.data.copy()
    
    # å¾æ‰€æœ‰ç·¨è¼¯å™¨ä¸­æ”¶é›†æœ€æ–°çš„ 'æ¨™è¨˜åˆªé™¤' ç‹€æ…‹
    deletion_updates = []
    for _, edited_df in st.session_state.edited_dataframes.items():
        if not edited_df.empty and 'æ¨™è¨˜åˆªé™¤' in edited_df.columns:
            deletion_updates.append(edited_df[['ID', 'æ¨™è¨˜åˆªé™¤']])
            
    if deletion_updates:
        combined_updates = pd.concat(deletion_updates)
        temp_df.set_index('ID', inplace=True)
        combined_updates.set_index('ID', inplace=True)
        temp_df.update(combined_updates)
        temp_df.reset_index(inplace=True)

    # çµ±è¨ˆè¦åˆªé™¤çš„ ID
    temp_df['æ¨™è¨˜åˆªé™¤'] = temp_df['æ¨™è¨˜åˆªé™¤'].apply(lambda x: True if x == True or str(x).lower() == 'true' else False)
    ids_to_delete = temp_df[temp_df['æ¨™è¨˜åˆªé™¤'] == True]['ID'].tolist()
    
    if not ids_to_delete:
        st.warning("âš ï¸ æ²’æœ‰é …ç›®è¢«æ¨™è¨˜ç‚ºåˆªé™¤ã€‚")
        st.session_state.show_delete_confirm = False
        return

    st.session_state.delete_count = len(ids_to_delete)
    st.session_state.ids_pending_delete = ids_to_delete 
    st.session_state.show_delete_confirm = True
    st.rerun()

def handle_batch_delete_quotes():
    """åŸ·è¡Œæ‰¹æ¬¡åˆªé™¤æ“ä½œã€‚"""
    ids_to_delete = st.session_state.get('ids_pending_delete', [])
    
    if not ids_to_delete:
        st.session_state.show_delete_confirm = False
        st.rerun()
        return
    
    current_data = st.session_state.data
    # å‰µå»ºæ–°çš„ DataFrameï¼Œæ’é™¤å¾…åˆªé™¤ ID
    new_data = current_data[~current_data['ID'].isin(ids_to_delete)].reset_index(drop=True)
    
    st.session_state.data = new_data
    
    # æ¸…ç†ç‹€æ…‹
    st.session_state.show_delete_confirm = False
    st.session_state.delete_count = 0
    st.session_state.ids_pending_delete = []
    
    save_and_rerun(st.session_state.data, st.session_state.project_metadata, f"âœ… å·²æ°¸ä¹…åˆªé™¤ {len(ids_to_delete)} ç­†è³‡æ–™ã€‚")


# ==============================================================================
# æ‡‰ç”¨ç¨‹å¼é€²å…¥é»èˆ‡é‹è¡Œé‚è¼¯
# ==============================================================================

def run_app():
    """æ‡‰ç”¨ç¨‹å¼çš„ä¸»é‹è¡Œé‚è¼¯ï¼Œåƒ…åœ¨ç™»å…¥æˆåŠŸå¾ŒåŸ·è¡Œã€‚"""
    st.title(f"ğŸ› ï¸ å°ˆæ¡ˆæ¡è³¼ç®¡ç†å·¥å…· {APP_VERSION}")
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    
    # --- åˆå§‹åŒ–æ•¸æ“šç‹€æ…‹ ---
    if 'data' not in st.session_state:
        d, m = load_data_from_sheets()
        st.session_state.data = d
        st.session_state.project_metadata = m
    
    # åˆå§‹åŒ– next_id å’Œç·¨è¼¯ç‹€æ…‹
    if 'next_id' not in st.session_state:
        st.session_state.next_id = st.session_state.data['ID'].max() + 1 if not st.session_state.data.empty and pd.notna(st.session_state.data['ID'].max()) else 1
    if 'edited_dataframes' not in st.session_state: st.session_state.edited_dataframes = {}

    # --- æ¯æ¬¡é‹è¡Œé‡æ–°è¨ˆç®—é—œéµæ•¸æ“š ---
    st.session_state.data = calculate_latest_arrival(st.session_state.data, st.session_state.project_metadata)
    
    # å»ºç«‹ äº¤æœŸç‹€æ…‹ (ç´…ç¶ ç‡ˆ)
    def get_status_icon(row):
        """ç”ŸæˆæœŸé™åˆ¤å®šæ¬„ä½çš„é¡¯ç¤ºå…§å®¹ï¼Œä½¿ç”¨ Emoji å’Œæ–‡å­— (é HTML)ã€‚"""
        try:
            proj_date = pd.to_datetime(row['é è¨ˆäº¤è²¨æ—¥']).date()
            latest_date = pd.to_datetime(row['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥']).date()
            
            # ä¿®å¾©: ç§»é™¤ HTML spanï¼Œç›´æ¥è¿”å› Emoji å’Œæ–‡å­—ä»¥å…¼å®¹èˆŠç‰ˆ Streamlit
            if proj_date > latest_date:
                 return "ğŸ”´ è½å¾Œ" 
            elif proj_date <= latest_date:
                 return "âœ… æ­£å¸¸"
            else:
                 return "N/A"
        except: return "N/A"
    
    if not st.session_state.data.empty:
        # ä½¿ç”¨ TextColumn æ¸²æŸ“å­—ä¸²
        st.session_state.data['äº¤æœŸç‹€æ…‹'] = st.session_state.data.apply(get_status_icon, axis=1)

    df = st.session_state.data
    
    # ==========================
    #      å´é‚Šæ¬„ (Sidebar UI)
    # ==========================
    with st.sidebar:
        st.button("ğŸšª ç™»å‡ºç³»çµ±", on_click=logout, type="secondary", use_container_width=True)
        st.markdown("---")
        
        # 1. ä¿®æ”¹/åˆªé™¤å°ˆæ¡ˆ (å®Œæ•´å€å¡Š)
        with st.expander("âœï¸ ä¿®æ”¹/åˆªé™¤å°ˆæ¡ˆè³‡è¨Š", expanded=False):
            all_projects = sorted(list(st.session_state.project_metadata.keys()))
            if all_projects:
                target_proj = st.selectbox("é¸æ“‡ç›®æ¨™å°ˆæ¡ˆ", all_projects, key="edit_target_project")
                operation = st.selectbox("é¸æ“‡æ“ä½œ", ("ä¿®æ”¹å°ˆæ¡ˆè³‡è¨Š", "åˆªé™¤å°ˆæ¡ˆ"), key="project_operation_select")
                st.markdown("---")
                
                current_meta = st.session_state.project_metadata.get(target_proj, {'due_date': datetime.now().date()})
                
                if operation == "ä¿®æ”¹å°ˆæ¡ˆè³‡è¨Š":
                    st.text_input("æ–°å°ˆæ¡ˆåç¨±", value=target_proj, key="edit_new_name")
                    st.date_input("æ–°å°ˆæ¡ˆäº¤è²¨æ—¥", value=current_meta['due_date'], key="edit_new_date")
                    if st.button("ç¢ºèªä¿®æ”¹å°ˆæ¡ˆ", type="primary", use_container_width=True): 
                        handle_project_modification()
                elif operation == "åˆªé™¤å°ˆæ¡ˆ":
                    st.warning(f"âš ï¸ ç¢ºèªæ°¸ä¹…åˆªé™¤å°ˆæ¡ˆ [{target_proj}]ï¼Ÿ")
                    if st.button("ğŸ”¥ ç¢ºèªæ°¸ä¹…åˆªé™¤", type="secondary", use_container_width=True): 
                        handle_delete_project(target_proj)
            else: 
                st.info("ç›®å‰ç„¡å°ˆæ¡ˆè³‡æ–™ã€‚è«‹åœ¨ä¸‹æ–¹æ–°å¢ã€‚")
        
        st.markdown("---")
        
        # 2. æ–°å¢å°ˆæ¡ˆ (å®Œæ•´å€å¡Š)
        with st.expander("â• æ–°å¢/è¨­å®šå°ˆæ¡ˆæ™‚ç¨‹", expanded=False):
            st.text_input("å°ˆæ¡ˆåç¨±", key="new_proj_name", placeholder="ä¾‹å¦‚: è¾¦å…¬å®¤å‡ç´š")
            project_due_date = st.date_input("å°ˆæ¡ˆäº¤è²¨æ—¥", value=datetime.now().date() + timedelta(days=30), key="new_proj_due_date")
            buffer_days = st.number_input("æ¡è³¼ç·©è¡å¤©æ•¸", min_value=0, value=7, key="new_proj_buffer_days")
            
            calc_date = project_due_date - timedelta(days=int(buffer_days))
            st.info(f"ğŸ“… è¨ˆç®—ä¹‹æœ€æ…¢åˆ°è²¨æ—¥ï¼š{calc_date.strftime(DATE_FORMAT)}")
            
            if st.button("ğŸ’¾ å„²å­˜å°ˆæ¡ˆè¨­å®š", key="btn_save_proj", use_container_width=True): 
                handle_add_new_project()

        st.markdown("---")
        
        # 3. æ–°å¢å ±åƒ¹ (å®Œæ•´å€å¡Šï¼ŒåŒ…å«ã€Œå·¥ä½œæ—¥æ•¸ã€é¸é …)
        with st.expander("â• æ–°å¢å ±åƒ¹", expanded=True):
            all_projects_for_quote = sorted(list(st.session_state.project_metadata.keys()))
            latest_arrival_date = datetime.now().date()
            
            if not all_projects_for_quote:
                st.warning("è«‹å…ˆåœ¨ä¸Šæ–¹æ–°å¢å°ˆæ¡ˆã€‚")
                project_name = None
            else:
                st.session_state.quote_project_select = st.selectbox("æ­¸å±¬å°ˆæ¡ˆ", all_projects_for_quote, key="quote_project_select_sb")
                current_meta = st.session_state.project_metadata.get(st.session_state.quote_project_select, {'due_date': datetime.now().date(), 'buffer_days': 7})
                latest_arrival_date = current_meta['due_date'] - timedelta(days=int(current_meta['buffer_days']))
                st.caption(f"æ­¤å°ˆæ¡ˆæœ€æ…¢åˆ°è²¨æœŸé™: {latest_arrival_date.strftime(DATE_FORMAT)}")

            unique_items = sorted([x for x in df['å°ˆæ¡ˆé …ç›®'].unique() if x])
            selected_item = st.selectbox("æ¡è³¼é …ç›®", ['ğŸ†• æ–°é …ç›®'] + unique_items, key="quote_item_select")
            
            if selected_item == 'ğŸ†• æ–°é …ç›®':
                item_name_to_use = st.text_input("è¼¸å…¥æ–°é …ç›®åç¨±", key="quote_item_new_input")
            else:
                item_name_to_use = selected_item
            st.session_state.item_name_to_use_final = item_name_to_use
            
            col_sup, col_pr = st.columns(2)
            st.session_state.quote_supplier = col_sup.text_input("ä¾›æ‡‰å•†", key="quote_supplier_input")
            st.session_state.quote_price = col_pr.number_input("å–®åƒ¹", min_value=0.0, key="quote_price_input")
            st.session_state.quote_qty = st.number_input("æ•¸é‡", min_value=1, value=1, key="quote_qty_input")
            
            st.markdown("---")
            st.markdown("ğŸ“† **é è¨ˆäº¤è²¨æ—¥è¨­å®š**", unsafe_allow_html=True)
            # é‡æ–°å¼•å…¥ 3. å·¥ä½œæ—¥æ•¸ é¸é …
            date_input_type = st.radio("è¼¸å…¥æ–¹å¼", ("1. æŒ‡å®šæ—¥æœŸ", "2. è‡ªç„¶æ—¥æ•¸", "3. å·¥ä½œæ—¥æ•¸"), key="quote_date_type", horizontal=True)
            
            today = datetime.now().date()
            if date_input_type == "1. æŒ‡å®šæ—¥æœŸ": 
                st.session_state.quote_delivery_date = st.date_input("é¸æ“‡æ—¥æœŸ", today, key="quote_delivery_date_input") 
            elif date_input_type == "2. è‡ªç„¶æ—¥æ•¸": 
                num_days = st.number_input("å¹¾å¤©å¾Œäº¤è²¨?", 1, value=7, key="quote_num_days_input")
                st.session_state.calculated_delivery_date = today + timedelta(days=int(num_days))
                st.info(f"è¨ˆç®—çµæœï¼š{st.session_state.calculated_delivery_date.strftime(DATE_FORMAT)}")
            elif date_input_type == "3. å·¥ä½œæ—¥æ•¸": 
                num_b_days = st.number_input("å¹¾å€‹å·¥ä½œå¤©?", 1, value=5, key="quote_num_b_days_input")
                st.session_state.calculated_delivery_date = add_business_days(today, int(num_b_days))
                st.info(f"è¨ˆç®—çµæœï¼š{st.session_state.calculated_delivery_date.strftime(DATE_FORMAT)}")
            
            st.session_state.quote_status = st.selectbox("åˆå§‹ç‹€æ…‹", STATUS_OPTIONS, key="quote_status_select")
            
            st.markdown("ğŸ“ **é™„ä»¶ä¸Šå‚³**", unsafe_allow_html=True)
            uploaded_file = st.file_uploader("æ”¯æ´ PDF/åœ–ç‰‡", type=['pdf', 'jpg', 'jpeg', 'png'], key="new_quote_file_uploader")

            if st.button("ğŸ“¥ æ–°å¢è³‡æ–™", key="btn_add_quote", type="primary", use_container_width=True):
                handle_add_new_quote(latest_arrival_date, uploaded_file)


    # ==========================
    #      ä¸»ç•«é¢ (Main UI)
    # ==========================
    
    # å„€è¡¨æ¿ Metrics
    n, b, r, p = calculate_metrics(df, st.session_state.project_metadata)
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("å°ˆæ¡ˆæ•¸", n)
    c2.metric("ç¸½é ç®—", f"${b:,.0f}")
    c3.metric("é¢¨éšªé …", r)
    c4.metric("å¾…è™•ç†", p)
    
    st.markdown("---")
    
    # å„²å­˜/åˆªé™¤å·¥å…·åˆ—
    col_save, col_delete = st.columns([0.8, 0.2])
    with col_save:
        if st.button("ğŸ’¾ å„²å­˜æ‰€æœ‰è¡¨æ ¼ä¿®æ”¹ (ä¸¦é‡æ–°è¨ˆç®—ç¸½åƒ¹)", type="primary"): 
            handle_master_save()
    with col_delete:
        if st.button("ğŸ—‘ï¸ åˆªé™¤å·²æ¨™è¨˜é …ç›®", type="secondary"):
            trigger_delete_confirmation()

    # åˆªé™¤ç¢ºèªå°è©±æ¡†
    if st.session_state.get('show_delete_confirm'):
        st.error(f"âš ï¸ ç¢ºèªæ°¸ä¹…åˆªé™¤ {st.session_state.delete_count} ç­†è³‡æ–™ï¼Ÿæ­¤æ“ä½œä¸å¯å¾©åŸï¼")
        cy, cn, _ = st.columns([0.15, 0.15, 0.7])
        with cy: 
            if st.button("âœ… ç¢ºèªåˆªé™¤", key="confirm_delete_yes", type="primary"): handle_batch_delete_quotes()
        with cn: 
            if st.button("âŒ å–æ¶ˆ", key="confirm_delete_no"): st.session_state.show_delete_confirm = False
    
    st.markdown("---")

    # ä¸»è¦å ±åƒ¹è¡¨æ ¼
    if df.empty:
        st.info("ğŸ‘‹ æ­¡è¿ä½¿ç”¨ï¼ç›®å‰æ²’æœ‰è³‡æ–™ï¼Œè«‹å¾å·¦å´å´é‚Šæ¬„æ–°å¢å°ˆæ¡ˆèˆ‡å ±åƒ¹ã€‚")
        
    for proj_name, proj_data in df.groupby('å°ˆæ¡ˆåç¨±'):
        meta = st.session_state.project_metadata.get(proj_name, {})
        
        # å°ˆæ¡ˆ HTML Header (V2.1.6 æ¨£å¼)
        st.markdown(f"""
        <div class="project-card-header">
            <span class="proj-title">ğŸ’¼ {proj_name}</span>
            <span class="proj-meta"> | äº¤æœŸ: {meta.get('due_date')}</span>
            <span class="proj-budget">${calculate_project_budget(proj_data, proj_name):,.0f}</span>
        </div>
        """, unsafe_allow_html=True)
        
        with st.expander("å±•é–‹æ˜ç´°", expanded=True):
            for item_name, item_data in proj_data.groupby('å°ˆæ¡ˆé …ç›®'):
                st.markdown(f"<div class='item-header'>ğŸ“¦ {item_name}</div>", unsafe_allow_html=True)
                
                # --- æº–å‚™é¡¯ç¤ºç”¨çš„ DataFrame ---
                display = item_data.copy()
                display['é™„ä»¶é€£çµ'] = None
                # é å…ˆç”Ÿæˆ Signed URL
                for idx, row in display.iterrows():
                    if row.get('é™„ä»¶URL'):
                        url = generate_signed_url_cached(row['é™„ä»¶URL'])
                        if url: display.at[idx, 'é™„ä»¶é€£çµ'] = url
                
                # Column Config
                cols = ['ID', 'é¸å–', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 
                        'é è¨ˆäº¤è²¨æ—¥', 'äº¤æœŸç‹€æ…‹', 'ç‹€æ…‹', 'é™„ä»¶é€£çµ', 'æœ€å¾Œä¿®æ”¹æ™‚é–“', 'æ¨™è¨˜åˆªé™¤']
                
                edited = st.data_editor(
                    display[cols],
                    column_config={
                        # æ ¸å¿ƒæ¬„ä½
                        "ID": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                        "é¸å–": st.column_config.CheckboxColumn("é¸", width="small"),
                        "ç¸½åƒ¹": st.column_config.NumberColumn(format="$%d", disabled=True),
                        # V2.2.6/7: å°‡é è¨ˆäº¤è²¨æ—¥æ”¹ç‚º DateColumn æ–¹ä¾¿ä¿®æ”¹
                        "é è¨ˆäº¤è²¨æ—¥": st.column_config.DateColumn("é è¨ˆäº¤è²¨æ—¥", format="YYYY-MM-DD", help="é»æ“Šä¿®æ”¹æ—¥æœŸ"), 
                        
                        # æ–°å¢çš„è¿½è¹¤æ¬„ä½
                        # FIX: å°‡ HtmlColumn æ”¹ç‚º TextColumn é¿å… AttributeError
                        "äº¤æœŸç‹€æ…‹": st.column_config.TextColumn("æœŸé™åˆ¤å®š", disabled=True, width="small"), 
                        "æœ€å¾Œä¿®æ”¹æ™‚é–“": st.column_config.TextColumn("æœ€å¾Œä¿®æ”¹", disabled=True, width="medium"), # å ±åƒ¹æ™‚é–“æˆ³
                        
                        # GCS é€£çµ
                        "é™„ä»¶é€£çµ": st.column_config.LinkColumn("é™„ä»¶", display_text="ğŸ“„ é–‹å•Ÿ", width="small"),
                        
                        # åˆªé™¤æ¨™è¨˜
                        "æ¨™è¨˜åˆªé™¤": st.column_config.CheckboxColumn("åˆªé™¤?", width="small"),
                        
                        # éš±è—åŸå§‹ç³»çµ±è·¯å¾‘
                        "é™„ä»¶URL": None 
                    },
                    hide_index=True,
                    key=f"ed_{proj_name}_{item_name}",
                    num_rows="dynamic" # å…è¨±å‹•æ…‹æ–°å¢è¡Œ
                )
                st.session_state.edited_dataframes[item_name] = edited
            st.markdown("<br>", unsafe_allow_html=True)

def main():
    login_form()
    if st.session_state.authenticated: run_app()

if __name__ == "__main__":
    main()
