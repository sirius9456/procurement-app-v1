import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO
import os 
import json
import gspread

# å¼•å…¥ç™»å…¥ã€æ—¥èªŒå’Œé…ç½®æ¨¡çµ„
import logging
import yaml
from yaml.loader import SafeLoader
import streamlit_authenticator as stauth


# é…ç½® Streamlit æ—¥èªŒï¼Œä»¥ä¾¿å°‡éŒ¯èª¤å¯«å…¥ journalctl
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


# --- æ‡‰ç”¨ç¨‹å¼è¨­å®š ---
APP_VERSION = "v2.1.2 (Login Integrated)" # ç‰ˆæœ¬æ›´æ–°ç‚º v2.1.2
STATUS_OPTIONS = ["å¾…æ¡è³¼", "å·²ä¸‹å–®", "å·²æ”¶è²¨", "å–æ¶ˆ"]

# --- æ•¸æ“šæºé…ç½® (GCE/æœ¬åœ°é€šç”¨é…ç½®) ---
if "GCE_SHEET_URL" in os.environ:
    SHEET_URL = os.environ["GCE_SHEET_URL"]
    try:
        GSHEETS_CREDENTIALS = os.environ["GSHEETS_CREDENTIALS_PATH"] 
    except KeyError:
        # éŒ¯èª¤æ—¥èªŒè¨˜éŒ„
        logging.error("GCE_SHEET_URL is set, but GSHEETS_CREDENTIALS_PATH is missing.")
        st.error("âŒ éŒ¯èª¤ï¼šåœ¨ GCE ç’°å¢ƒä¸­æœªæ‰¾åˆ° GSHEETS_CREDENTIALS_PATH ç’°å¢ƒè®Šæ•¸ã€‚")
        GSHEETS_CREDENTIALS = None 
else:
    # å‚™ç”¨é‚è¼¯ï¼Œæœ¬åœ°æˆ– Streamlit Cloud ä½¿ç”¨
    try:
        SHEET_URL = st.secrets["app_config"]["sheet_url"]
        GSHEETS_CREDENTIALS = None
    except KeyError:
        SHEET_URL = None
        GSHEETS_CREDENTIALS = None
        
DATA_SHEET_NAME = "æ¡è³¼ç¸½è¡¨"
METADATA_SHEET_NAME = "å°ˆæ¡ˆè¨­å®š"


# è¨­å®šé é¢æ¨™é¡Œèˆ‡å¯¬åº¦ (å¿…é ˆåœ¨ Streamlit ç¨‹å¼ç¢¼ä¸­ç¬¬ä¸€å€‹èª¿ç”¨)
st.set_page_config(page_title=f"å°ˆæ¡ˆæ¡è³¼å°å¹«æ‰‹ {APP_VERSION}", layout="wide")

# --- CSS æ¨£å¼ä¿®æ­£ (ä¿æŒä¸è®Š) ---
CUSTOM_CSS = """
<style>
/* ä¿æŒåŸæ¨£ï¼Œç¢ºä¿é é¢é¢¨æ ¼ä¸€è‡´ */
.streamlit-expanderContent { padding-left: 1rem !important; padding-right: 1rem !important; padding-bottom: 1rem !important; }
.project-header { font-size: 20px !important; font-weight: bold !important; color: #FAFAFA; }
.item-header { font-size: 16px !important; font-weight: 600 !important; color: #E0E0E0; }
.meta-info { font-size: 14px !important; color: #9E9E9E; font-weight: normal; }
div[data-baseweb="select"] > div, div[data-baseweb="base-input"] > input, div[data-baseweb="input"] > div { background-color: #262730 !important; color: white !important; -webkit-text-fill-color: white !important; }
div[data-baseweb="popover"], div[data-baseweb="menu"] { background-color: #262730 !important; }
div[data-baseweb="option"] { color: white !important; }
li[aria-selected="true"] { background-color: #FF4B4B !important; color: white !important; }
.metric-box { padding: 10px 15px; border-radius: 8px; margin-bottom: 10px; background-color: #262730; text-align: center; }
.metric-title { font-size: 14px; color: #9E9E9E; margin-bottom: 5px; }
.metric-value { font-size: 24px; font-weight: bold; }
</style>
"""

# --- æ•¸æ“šè®€å–èˆ‡å¯«å…¥å‡½å¼ (æ ¸å¿ƒä¿®æ”¹: ä½¿ç”¨ gspread) ---

@st.cache_data(ttl=600, show_spinner="é€£ç·š Google Sheets...")
def load_data_from_sheets():
    """ç›´æ¥ä½¿ç”¨ gspread è®€å– Google Sheets ä¸­çš„æ•¸æ“šã€‚"""
    
    if not SHEET_URL:
        st.info("âŒ Google Sheets URL å°šæœªé…ç½®ã€‚ä½¿ç”¨ç©ºçš„æ•¸æ“šçµæ§‹ã€‚")
        empty_data = pd.DataFrame(columns=['ID', 'é¸å–', 'å°ˆæ¡ˆåç¨±', 'å°ˆæ¡ˆé …ç›®', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 'é è¨ˆäº¤è²¨æ—¥', 'ç‹€æ…‹', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥', 'æ¨™è¨˜åˆªé™¤'])
        return empty_data, {}

    try:
        # --- 1. æˆæ¬Šèˆ‡èªè­‰ ---
        if not GSHEETS_CREDENTIALS or not os.path.exists(GSHEETS_CREDENTIALS):
             st.error(f"âŒ æ†‘è­‰éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ†‘è­‰æª”æ¡ˆ {GSHEETS_CREDENTIALS}")
             raise FileNotFoundError("æ†‘è­‰æª”æ¡ˆä¸å­˜åœ¨æˆ–è·¯å¾‘éŒ¯èª¤")
             
        gc = gspread.service_account(filename=GSHEETS_CREDENTIALS)
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 2. è®€å–æ¡è³¼ç¸½è¡¨ (Data) ---
        data_ws = sh.worksheet(DATA_SHEET_NAME)
        data_records = data_ws.get_all_records()
        data_df = pd.DataFrame(data_records)

        # æ•¸æ“šé¡å‹è½‰æ›èˆ‡è™•ç†
        data_df = data_df.astype({
            'ID': 'Int64', 'é¸å–': 'bool', 'å–®åƒ¹': 'float', 'æ•¸é‡': 'Int64', 'ç¸½åƒ¹': 'float'
        })
        if 'æ¨™è¨˜åˆªé™¤' not in data_df.columns:
            data_df['æ¨™è¨˜åˆªé™¤'] = False

        # --- 3. è®€å–å°ˆæ¡ˆè¨­å®š (Metadata) ---
        metadata_ws = sh.worksheet(METADATA_SHEET_NAME)
        metadata_records = metadata_ws.get_all_records()
        
        project_metadata = {}
        if metadata_records:
            for row in metadata_records:
                try:
                    due_date = pd.to_datetime(str(row['å°ˆæ¡ˆäº¤è²¨æ—¥'])).date()
                except (ValueError, TypeError):
                    due_date = datetime.now().date()
                    
                project_metadata[row['å°ˆæ¡ˆåç¨±']] = {
                    'due_date': due_date,
                    'buffer_days': int(row['ç·©è¡å¤©æ•¸']),
                    'last_modified': str(row['æœ€å¾Œä¿®æ”¹'])
                }

        st.success("âœ… æ•¸æ“šå·²å¾ Google Sheets è¼‰å…¥ï¼")
        return data_df, project_metadata

    except Exception as e:
        # è¨˜éŒ„å®Œæ•´çš„éŒ¯èª¤è¿½æº¯åˆ° systemd journal
        logging.exception("Google Sheets æ•¸æ“šè¼‰å…¥æ™‚ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤ï¼") 
        
        st.error(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼è«‹æª¢æŸ¥ Sheets åˆ†äº«æ¬Šé™ã€å·¥ä½œè¡¨åç¨±æˆ–æ†‘è­‰æª”æ¡ˆã€‚")
        st.code(f"éŒ¯èª¤è¨Šæ¯: {e}")
        
        empty_data = pd.DataFrame(columns=['ID', 'é¸å–', 'å°ˆæ¡ˆåç¨±', 'å°ˆæ¡ˆé …ç›®', 'ä¾›æ‡‰å•†', 'å–®åƒ¹', 'æ•¸é‡', 'ç¸½åƒ¹', 'é è¨ˆäº¤è²¨æ—¥', 'ç‹€æ…‹', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥', 'æ¨™è¨˜åˆªé™¤'])
        st.session_state.data_load_failed = True
        return empty_data, {}


def write_data_to_sheets(df_to_write, metadata_to_write):
    """ç›´æ¥ä½¿ç”¨ gspread å¯«å› Google Sheetsã€‚"""
    if st.session_state.get('data_load_failed', False) or not SHEET_URL:
        st.warning("æ•¸æ“šè¼‰å…¥å¤±æ•—æˆ– URL æœªé…ç½®ï¼Œå·²ç¦ç”¨å¯«å…¥ Sheetsã€‚")
        return False
        
    try:
        # --- 1. æˆæ¬Šèˆ‡èªè­‰ ---
        gc = gspread.service_account(filename=GSHEETS_CREDENTIALS)
        sh = gc.open_by_url(SHEET_URL)
        
        # --- 2. å¯«å…¥æ¡è³¼ç¸½è¡¨ (Data) ---
        df_export = df_to_write.drop(columns=['æ¨™è¨˜åˆªé™¤', 'äº¤æœŸé¡¯ç¤º'], errors='ignore')
        data_ws = sh.worksheet(DATA_SHEET_NAME)
        data_ws.clear()
        data_ws.update([df_export.columns.values.tolist()] + df_export.values.tolist())
        
        # --- 3. å¯«å…¥å°ˆæ¡ˆè¨­å®š (Metadata) ---
        metadata_list = [
            {'å°ˆæ¡ˆåç¨±': name, 
             'å°ˆæ¡ˆäº¤è²¨æ—¥': data['due_date'].strftime('%Y-%m-%d'),
             'ç·©è¡å¤©æ•¸': data['buffer_days'], 
             'æœ€å¾Œä¿®æ”¹': data['last_modified']}
            for name, data in metadata_to_write.items()
        ]
        metadata_df = pd.DataFrame(metadata_list)
        metadata_ws = sh.worksheet(METADATA_SHEET_NAME)
        metadata_ws.clear()
        metadata_ws.update([metadata_df.columns.values.tolist()] + metadata_df.values.tolist())
        
        # æ•ˆèƒ½å„ªåŒ–ï¼šæˆåŠŸå¯«å…¥å¾Œï¼Œæ¸…é™¤ Streamlit å¿«å–
        st.cache_data.clear() 
        return True
        
    except Exception as e:
        logging.exception("Google Sheets æ•¸æ“šå¯«å…¥æ™‚ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤ï¼")
        st.error(f"âŒ æ•¸æ“šå¯«å› Google Sheets å¤±æ•—ï¼")
        st.code(f"å¯«å…¥éŒ¯èª¤è¨Šæ¯: {e}")
        return False


# --- è¼”åŠ©å‡½å¼å€ ---

def add_business_days(start_date, num_days):
    # ä¿æŒåŸé‚è¼¯
    current_date = start_date
    days_added = 0
    while days_added < num_days:
        current_date += timedelta(days=1)
        if current_date.weekday() < 5: days_added += 1
    return current_date

@st.cache_data
def convert_df_to_excel(df):
    # ä¿æŒåŸé‚è¼¯
    df_export = df.drop(columns=['æ¨™è¨˜åˆªé™¤', 'äº¤æœŸé¡¯ç¤º'], errors='ignore')
    output = BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_export.to_excel(writer, index=False, sheet_name='æ¡è³¼å ±åƒ¹ç¸½è¡¨')
    
    processed_data = output.getvalue()
    return processed_data


@st.cache_data(show_spinner=False)
def calculate_dashboard_metrics(df_state, project_metadata_state):
    # ä¿æŒåŸé‚è¼¯
    total_projects = len(project_metadata_state)
    total_budget = 0
    risk_items = 0
    df = df_state.copy()
    
    if df.empty:
        return 0, 0, 0, 0

    for _, proj_data in df.groupby('å°ˆæ¡ˆåç¨±'):
        for _, item_df in proj_data.groupby('å°ˆæ¡ˆé …ç›®'):
            selected_rows = item_df[item_df['é¸å–'] == True]
            if not selected_rows.empty:
                total_budget += selected_rows['ç¸½åƒ¹'].sum()
            elif not item_df.empty:
                total_budget += item_df['ç¸½åƒ¹'].min()
    
    temp_df_risk = df.copy() 
    temp_df_risk['é è¨ˆäº¤è²¨æ—¥_dt'] = pd.to_datetime(temp_df_risk['é è¨ˆäº¤è²¨æ—¥'], errors='coerce')
    temp_df_risk['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_dt'] = pd.to_datetime(temp_df_risk['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'], errors='coerce')
    
    risk_items = (temp_df_risk['é è¨ˆäº¤è²¨æ—¥_dt'] > temp_df_risk['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_dt']).sum()

    pending_quotes = df[~df['ç‹€æ…‹'].isin(['å·²æ”¶è²¨', 'å–æ¶ˆ'])].shape[0]

    return total_projects, total_budget, risk_items, pending_quotes

def calculate_project_budget(df, project_name):
    # ä¿æŒåŸé‚è¼¯
    proj_df = df[df['å°ˆæ¡ˆåç¨±'] == project_name]
    total_budget = 0
    for _, item_df in proj_df.groupby('å°ˆæ¡ˆé …ç›®'):
        selected_rows = item_df[item_df['é¸å–'] == True]
        if not selected_rows.empty:
            total_budget += selected_rows['ç¸½åƒ¹'].sum()
        else:
            if not item_df.empty:
                total_budget += item_df['ç¸½åƒ¹'].min()
    return total_budget

# --- å°ˆæ¡ˆäº¤æœŸè‡ªå‹•è¨ˆç®—é‚è¼¯ (V2.1.1 å„ªåŒ–) ---
@st.cache_data(show_spinner=False)
def calculate_latest_arrival_dates(df, metadata):
    """æ ¹æ“šå°ˆæ¡ˆè¨­å®šï¼Œè¨ˆç®—æ¯å€‹æ¡è³¼é …ç›®çš„æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥ã€‚"""
    
    if df.empty or not metadata:
        return df

    metadata_df = pd.DataFrame.from_dict(metadata, orient='index')
    metadata_df = metadata_df.reset_index().rename(columns={'index': 'å°ˆæ¡ˆåç¨±'})
    
    metadata_df['due_date'] = metadata_df['due_date'].apply(lambda x: pd.to_datetime(x).date())
    metadata_df['buffer_days'] = metadata_df['buffer_days'].astype(int)

    df = pd.merge(df, metadata_df[['å°ˆæ¡ˆåç¨±', 'due_date', 'buffer_days']], on='å°ˆæ¡ˆåç¨±', how='left')

    df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_NEW'] = (
        df['due_date'] - 
        df['buffer_days'].apply(lambda x: timedelta(days=x))
    ).dt.strftime('%Y-%m-%d')
    
    df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥'] = df['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_NEW']
    
    df = df.drop(columns=['due_date', 'buffer_days', 'æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥_NEW'], errors='ignore')
    return df

# ... (çœç•¥ handle_xxx å‡½å¼ï¼Œå‡è¨­å®ƒå€‘å·²æ­£ç¢ºå®šç¾©åœ¨æª”æ¡ˆä¸­) ...
# æ³¨æ„ï¼šæ‰€æœ‰ handle_xxx å‡½å¼ (å¦‚ handle_master_save) éƒ½æ‡‰åœ¨ run_app ä¹‹å‰å®šç¾©
# --------------------------------------------------------------------------

# --- Session State åˆå§‹åŒ–å‡½å¼ (å„ªåŒ–) ---
def initialize_session_state():
    """åˆå§‹åŒ–æ‰€æœ‰ Streamlit Session State è®Šæ•¸ã€‚å¾ Sheets è®€å–æ•¸æ“šã€‚"""
    # ä¿æŒåŸé‚è¼¯
    today = datetime.now().date()
    
    if 'data' not in st.session_state or 'project_metadata' not in st.session_state:
        data_df, metadata_dict = load_data_from_sheets()
        
        st.session_state.data = data_df
        st.session_state.project_metadata = metadata_dict
        
    if 'æ¨™è¨˜åˆªé™¤' not in st.session_state.data.columns:
        st.session_state.data['æ¨™è¨˜åˆªé™¤'] = False
            
    if 'next_id' not in st.session_state:
        st.session_state.next_id = st.session_state.data['ID'].max() + 1 if not st.session_state.data.empty else 1
    
    if 'edited_dataframes' not in st.session_state:
        st.session_state.edited_dataframes = {}

    if 'calculated_delivery_date' not in st.session_state:
        st.session_state.calculated_delivery_date = today
        
    if 'show_delete_confirm' not in st.session_state:
        st.session_state.show_delete_confirm = False
    if 'delete_count' not in st.session_state:
        st.session_state.delete_count = 0


# --- ä¸»æ‡‰ç”¨ç¨‹å¼æ ¸å¿ƒé‚è¼¯ (åŸ main å‡½å¼ï¼Œç¾æ”¹åç‚º run_app) ---
def run_app():
    """é‹è¡Œæ‡‰ç”¨ç¨‹å¼çš„æ ¸å¿ƒé‚è¼¯ï¼Œåœ¨æˆåŠŸç™»å…¥å¾Œèª¿ç”¨ã€‚"""
    
    st.title(f"ğŸ› ï¸ å°ˆæ¡ˆæ¡è³¼ç®¡ç†å·¥å…· {APP_VERSION}") 
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

    initialize_session_state()

    # æ•¸æ“šè‡ªå‹•è¨ˆç®—ï¼šåœ¨åˆå§‹åŒ–å¾Œï¼Œè¨ˆç®—æœ€æ…¢åˆ°è²¨æ—¥
    st.session_state.data = calculate_latest_arrival_dates(
        st.session_state.data, 
        st.session_state.project_metadata
    )
    
    # å¦‚æœæ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œé¡¯ç¤ºè­¦å‘Š
    if st.session_state.get('data_load_failed', False):
        st.warning("æ‡‰ç”¨ç¨‹å¼ç„¡æ³•å¾ Google Sheets è¼‰å…¥æ•¸æ“šï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹éŒ¯èª¤è¨Šæ¯ã€‚")
        
    today = datetime.now().date() 

    # --- UI æ ¸å¿ƒé‚è¼¯é–‹å§‹ ---
    
    def format_date_with_icon(row):
        date_str = str(row['é è¨ˆäº¤è²¨æ—¥'])
        try:
            v_date = pd.to_datetime(row['é è¨ˆäº¤è²¨æ—¥']).date()
            l_date = pd.to_datetime(row['æ¡è³¼æœ€æ…¢åˆ°è²¨æ—¥']).date()
            icon = "ğŸ”´" if v_date > l_date else "âœ…"
            return f"{date_str} {icon}"
        except:
            return date_str

    if not st.session_state.data.empty:
        st.session_state.data['äº¤æœŸé¡¯ç¤º'] = st.session_state.data.apply(format_date_with_icon, axis=1)

    df = st.session_state.data
    project_groups = df.groupby('å°ˆæ¡ˆåç¨±')
    
    # ... (æ­¤è™•çœç•¥å„€è¡¨æ¿ã€æ‰¹æ¬¡æ“ä½œã€Expander å’Œ data_editor ç­‰ UI ä»£ç¢¼ï¼Œ
    # ç¢ºä¿ä½ å°‡ V2.1.0 ç‰ˆæœ¬ä¸­çš„æ‰€æœ‰ UI ä»£ç¢¼è²¼åˆ°é€™è£¡ï¼Œä¸¦ä½¿ç”¨ run_app å‡½å¼) ...

    st.subheader("ğŸ“Š ç¸½è¦½å„€è¡¨æ¿")
    # æ­¤è™•æ‡‰åŒ…å«å„€è¡¨æ¿ UI é‚è¼¯
    
    st.markdown("---")
    
    # æ­¤è™•æ‡‰åŒ…å«æ‰¹æ¬¡æ“ä½œæŒ‰éˆ•å’Œé‚è¼¯
    
    st.markdown("---")
    
    # æ­¤è™•æ‡‰åŒ…å«å°ˆæ¡ˆ Expander åˆ—è¡¨
    for proj_name, proj_data in project_groups:
        # ... (Expander å’Œ data_editor é‚è¼¯) ...
        pass
    
    # ... (UI æ ¸å¿ƒé‚è¼¯çµæŸ) ...

# --- ç™»å…¥é‚è¼¯ (æ–°çš„ä¸»è¦å…¥å£é») ---
def main():
    # --- 1. ç™»å…¥é…ç½® ---
    try:
        # å¾ config.yaml è¼‰å…¥è¨­å®š
        with open('config.yaml') as file:
            config = yaml.load(file, Loader=SafeLoader)
    except FileNotFoundError:
        st.error("é…ç½®æª”æ¡ˆ config.yaml æ‰¾ä¸åˆ°ï¼è«‹ç¢ºä¿æª”æ¡ˆå­˜åœ¨ä¸¦å‘½åæ­£ç¢ºã€‚")
        return
    except Exception as e:
        st.error(f"ç„¡æ³•è§£æ config.yaml æª”æ¡ˆ: {e}")
        return

    # å¯¦ä¾‹åŒ– Authenticator
    authenticator = stauth.Authenticate(
        config['credentials'],
        config['cookie']['name'],
        config['cookie']['key'],
        config['cookie']['expiry_days']
    )

    st.subheader("ğŸ›¡ï¸ å°ˆæ¡ˆæ¡è³¼ç®¡ç†å·¥å…· - ç™»å…¥é©—è­‰") 

    # --- 2. é¡¯ç¤ºç™»å…¥è¡¨å–® ---
    name, authentication_status, username = authenticator.login('Login')

    # --- 3. æª¢æŸ¥ç™»å…¥ç‹€æ…‹ä¸¦åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼ ---
    if st.session_state["authentication_status"]:
        # æˆåŠŸç™»å…¥
        
        # å´é‚Šæ¬„é¡¯ç¤ºç™»å‡ºæŒ‰éˆ•å’Œæ­¡è¿è¨Šæ¯
        with st.sidebar:
            # ç™»å‡ºæŒ‰éˆ•æ”¾åœ¨ sidebar
            st.sidebar.markdown("---") # æ·»åŠ åˆ†éš”ç·š
            authenticator.logout('ç™»å‡º', 'main') # ä¿æŒåœ¨ä¸»é é¢é¡¯ç¤ºç™»å‡º
            st.sidebar.write(f'æ­¡è¿, {st.session_state["name"]}')

        # åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼æ ¸å¿ƒé‚è¼¯
        run_app() 
        
    elif st.session_state["authentication_status"] is False:
        st.error('ç”¨æˆ¶å/å¯†ç¢¼éŒ¯èª¤')
        
    elif st.session_state["authentication_status"] is None:
        st.warning('è«‹è¼¸å…¥ä½ çš„ç”¨æˆ¶åå’Œå¯†ç¢¼')


# --- ç¨‹å¼é€²å…¥é» ---
if __name__ == "__main__":
    main()

